{
  "version": 3,
  "sources": ["../../src/index.ts", "../../src/init.ts", "../../src/utils/config.ts", "../../src/models/text.ts", "../../src/providers/openai.ts", "../../src/utils/events.ts", "../../src/models/embedding.ts", "../../src/models/image.ts", "../../src/models/audio.ts", "../../src/utils/audio.ts", "../../src/models/object.ts", "../../src/utils/json.ts", "../../src/models/tokenizer.ts", "../../src/utils/tokenization.ts"],
  "sourcesContent": [
    "import type {\n  DetokenizeTextParams,\n  GenerateTextParams,\n  IAgentRuntime,\n  ImageDescriptionParams,\n  ObjectGenerationParams,\n  Plugin,\n  TextEmbeddingParams,\n  TokenizeTextParams,\n} from \"@elizaos/core\";\nimport { logger, ModelType } from \"@elizaos/core\";\nimport { initializeOpenAI } from \"./init\";\nimport {\n  handleTextSmall,\n  handleTextLarge,\n  handleTextEmbedding,\n  handleImageGeneration,\n  handleImageDescription,\n  handleTranscription,\n  handleTextToSpeech,\n  handleObjectSmall,\n  handleObjectLarge,\n  handleTokenizerEncode,\n  handleTokenizerDecode,\n} from \"./models\";\nimport { getApiKey, getBaseURL, getAuthHeader } from \"./utils/config\";\n\nexport * from \"./types\";\n\n/**\n * Defines the OpenAI plugin with its name, description, and configuration options.\n * @type {Plugin}\n */\nexport const openaiPlugin: Plugin = {\n  name: \"openai\",\n  description: \"OpenAI plugin\",\n  config: {\n    OPENAI_API_KEY: process.env.OPENAI_API_KEY,\n    OPENAI_BASE_URL: process.env.OPENAI_BASE_URL,\n    OPENAI_SMALL_MODEL: process.env.OPENAI_SMALL_MODEL,\n    OPENAI_LARGE_MODEL: process.env.OPENAI_LARGE_MODEL,\n    SMALL_MODEL: process.env.SMALL_MODEL,\n    LARGE_MODEL: process.env.LARGE_MODEL,\n    OPENAI_EMBEDDING_MODEL: process.env.OPENAI_EMBEDDING_MODEL,\n    OPENAI_EMBEDDING_API_KEY: process.env.OPENAI_EMBEDDING_API_KEY,\n    OPENAI_EMBEDDING_URL: process.env.OPENAI_EMBEDDING_URL,\n    OPENAI_EMBEDDING_DIMENSIONS: process.env.OPENAI_EMBEDDING_DIMENSIONS,\n    OPENAI_IMAGE_DESCRIPTION_MODEL: process.env.OPENAI_IMAGE_DESCRIPTION_MODEL,\n    OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS:\n      process.env.OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS,\n    OPENAI_EXPERIMENTAL_TELEMETRY: process.env.OPENAI_EXPERIMENTAL_TELEMETRY,\n  },\n  async init(_config, runtime) {\n    // Note: We intentionally don't await here because ElizaOS expects\n    // the init method to return quickly. The initializeOpenAI function\n    // performs background validation and logging.\n    initializeOpenAI(_config, runtime);\n  },\n\n  models: {\n    [ModelType.TEXT_EMBEDDING]: async (\n      runtime: IAgentRuntime,\n      params: TextEmbeddingParams | string | null,\n    ) => {\n      return handleTextEmbedding(runtime, params);\n    },\n    [ModelType.TEXT_TOKENIZER_ENCODE]: async (\n      runtime: IAgentRuntime,\n      params: TokenizeTextParams,\n    ) => {\n      return handleTokenizerEncode(runtime, params);\n    },\n    [ModelType.TEXT_TOKENIZER_DECODE]: async (\n      runtime: IAgentRuntime,\n      params: DetokenizeTextParams,\n    ) => {\n      return handleTokenizerDecode(runtime, params);\n    },\n    [ModelType.TEXT_SMALL]: async (\n      runtime: IAgentRuntime,\n      params: GenerateTextParams,\n    ) => {\n      return handleTextSmall(runtime, params);\n    },\n    [ModelType.TEXT_LARGE]: async (\n      runtime: IAgentRuntime,\n      params: GenerateTextParams,\n    ) => {\n      return handleTextLarge(runtime, params);\n    },\n    [ModelType.IMAGE]: async (\n      runtime: IAgentRuntime,\n      params: {\n        prompt: string;\n        n?: number;\n        size?: string;\n      },\n    ) => {\n      return handleImageGeneration(runtime, params);\n    },\n    [ModelType.IMAGE_DESCRIPTION]: async (\n      runtime: IAgentRuntime,\n      params: ImageDescriptionParams | string,\n    ) => {\n      return handleImageDescription(runtime, params);\n    },\n    [ModelType.TRANSCRIPTION]: async (\n      runtime: IAgentRuntime,\n      input: Blob | File | Buffer | any,\n    ) => {\n      return handleTranscription(runtime, input);\n    },\n    [ModelType.TEXT_TO_SPEECH]: async (\n      runtime: IAgentRuntime,\n      input: string | any,\n    ) => {\n      return handleTextToSpeech(runtime, input);\n    },\n    [ModelType.OBJECT_SMALL]: async (\n      runtime: IAgentRuntime,\n      params: ObjectGenerationParams,\n    ) => {\n      return handleObjectSmall(runtime, params);\n    },\n    [ModelType.OBJECT_LARGE]: async (\n      runtime: IAgentRuntime,\n      params: ObjectGenerationParams,\n    ) => {\n      return handleObjectLarge(runtime, params);\n    },\n  },\n  tests: [\n    {\n      name: \"openai_plugin_tests\",\n      tests: [\n        {\n          name: \"openai_test_url_and_api_key_validation\",\n          fn: async (runtime: IAgentRuntime) => {\n            const baseURL = getBaseURL(runtime);\n            const response = await fetch(`${baseURL}/models`, {\n              headers: getAuthHeader(runtime),\n            });\n            const data = await response.json();\n            logger.log(\n              { data: (data as { data?: unknown[] })?.data?.length ?? \"N/A\" },\n              \"Models Available\",\n            );\n            if (!response.ok) {\n              throw new Error(\n                `Failed to validate OpenAI API key: ${response.statusText}`,\n              );\n            }\n          },\n        },\n        {\n          name: \"openai_test_text_embedding\",\n          fn: async (runtime: IAgentRuntime) => {\n            try {\n              const embedding = await runtime.useModel(\n                ModelType.TEXT_EMBEDDING,\n                {\n                  text: \"Hello, world!\",\n                },\n              );\n              logger.log({ embedding }, \"embedding\");\n            } catch (error: unknown) {\n              const message =\n                error instanceof Error ? error.message : String(error);\n              logger.error(`Error in test_text_embedding: ${message}`);\n              throw error;\n            }\n          },\n        },\n        {\n          name: \"openai_test_text_large\",\n          fn: async (runtime: IAgentRuntime) => {\n            try {\n              const text = await runtime.useModel(ModelType.TEXT_LARGE, {\n                prompt: \"What is the nature of reality in 10 words?\",\n              });\n              if (text.length === 0) {\n                throw new Error(\"Failed to generate text\");\n              }\n              logger.log({ text }, \"generated with test_text_large\");\n            } catch (error: unknown) {\n              const message =\n                error instanceof Error ? error.message : String(error);\n              logger.error(`Error in test_text_large: ${message}`);\n              throw error;\n            }\n          },\n        },\n        {\n          name: \"openai_test_text_small\",\n          fn: async (runtime: IAgentRuntime) => {\n            try {\n              const text = await runtime.useModel(ModelType.TEXT_SMALL, {\n                prompt: \"What is the nature of reality in 10 words?\",\n              });\n              if (text.length === 0) {\n                throw new Error(\"Failed to generate text\");\n              }\n              logger.log({ text }, \"generated with test_text_small\");\n            } catch (error: unknown) {\n              const message =\n                error instanceof Error ? error.message : String(error);\n              logger.error(`Error in test_text_small: ${message}`);\n              throw error;\n            }\n          },\n        },\n        {\n          name: \"openai_test_image_generation\",\n          fn: async (runtime: IAgentRuntime) => {\n            logger.log(\"openai_test_image_generation\");\n            try {\n              const image = await runtime.useModel(ModelType.IMAGE, {\n                prompt: \"A beautiful sunset over a calm ocean\",\n                n: 1,\n                size: \"1024x1024\",\n              });\n              logger.log({ image }, \"generated with test_image_generation\");\n            } catch (error: unknown) {\n              const message =\n                error instanceof Error ? error.message : String(error);\n              logger.error(`Error in test_image_generation: ${message}`);\n              throw error;\n            }\n          },\n        },\n        {\n          name: \"image-description\",\n          fn: async (runtime: IAgentRuntime) => {\n            try {\n              logger.log(\"openai_test_image_description\");\n              try {\n                const result = await runtime.useModel(\n                  ModelType.IMAGE_DESCRIPTION,\n                  \"https://upload.wikimedia.org/wikipedia/commons/thumb/1/1c/Vitalik_Buterin_TechCrunch_London_2015_%28cropped%29.jpg/537px-Vitalik_Buterin_TechCrunch_London_2015_%28cropped%29.jpg\",\n                );\n\n                if (\n                  result &&\n                  typeof result === \"object\" &&\n                  \"title\" in result &&\n                  \"description\" in result\n                ) {\n                  logger.log({ result }, \"Image description\");\n                } else {\n                  logger.error(\n                    \"Invalid image description result format:\",\n                    result,\n                  );\n                }\n              } catch (e: unknown) {\n                const message = e instanceof Error ? e.message : String(e);\n                logger.error(`Error in image description test: ${message}`);\n              }\n            } catch (e: unknown) {\n              const message = e instanceof Error ? e.message : String(e);\n              logger.error(\n                `Error in openai_test_image_description: ${message}`,\n              );\n            }\n          },\n        },\n        {\n          name: \"openai_test_transcription\",\n          fn: async (runtime: IAgentRuntime) => {\n            logger.log(\"openai_test_transcription\");\n            try {\n              const response = await fetch(\n                \"https://upload.wikimedia.org/wikipedia/en/4/40/Chris_Benoit_Voice_Message.ogg\",\n              );\n              const arrayBuffer = await response.arrayBuffer();\n              const transcription = await runtime.useModel(\n                ModelType.TRANSCRIPTION,\n                Buffer.from(new Uint8Array(arrayBuffer)),\n              );\n              logger.log(\n                { transcription },\n                \"generated with test_transcription\",\n              );\n            } catch (error: unknown) {\n              const message =\n                error instanceof Error ? error.message : String(error);\n              logger.error(`Error in test_transcription: ${message}`);\n              throw error;\n            }\n          },\n        },\n        {\n          name: \"openai_test_text_tokenizer_encode\",\n          fn: async (runtime: IAgentRuntime) => {\n            const prompt = \"Hello tokenizer encode!\";\n            const tokens = await runtime.useModel(\n              ModelType.TEXT_TOKENIZER_ENCODE,\n              { prompt },\n            );\n            if (!Array.isArray(tokens) || tokens.length === 0) {\n              throw new Error(\n                \"Failed to tokenize text: expected non-empty array of tokens\",\n              );\n            }\n            logger.log({ tokens }, \"Tokenized output\");\n          },\n        },\n        {\n          name: \"openai_test_text_tokenizer_decode\",\n          fn: async (runtime: IAgentRuntime) => {\n            const prompt = \"Hello tokenizer decode!\";\n            const tokens = await runtime.useModel(\n              ModelType.TEXT_TOKENIZER_ENCODE,\n              { prompt },\n            );\n            const decodedText = await runtime.useModel(\n              ModelType.TEXT_TOKENIZER_DECODE,\n              {\n                tokens,\n              },\n            );\n            if (decodedText !== prompt) {\n              throw new Error(\n                `Decoded text does not match original. Expected \"${prompt}\", got \"${decodedText}\"`,\n              );\n            }\n            logger.log({ decodedText }, \"Decoded text\");\n          },\n        },\n        {\n          name: \"openai_test_text_to_speech\",\n          fn: async (runtime: IAgentRuntime) => {\n            try {\n              const response = await runtime.useModel(\n                ModelType.TEXT_TO_SPEECH,\n                {\n                  text: \"Hello, this is a test for text-to-speech.\",\n                },\n              );\n              if (!response) {\n                throw new Error(\"Failed to generate speech\");\n              }\n              logger.log(\"Generated speech successfully\");\n            } catch (error: unknown) {\n              const message =\n                error instanceof Error ? error.message : String(error);\n              logger.error(`Error in openai_test_text_to_speech: ${message}`);\n              throw error;\n            }\n          },\n        },\n      ],\n    },\n  ],\n};\n\nexport default openaiPlugin;\n",
    "import { logger, type IAgentRuntime } from \"@elizaos/core\";\nimport {\n  getApiKey,\n  getAuthHeader,\n  getBaseURL,\n  isBrowser,\n} from \"./utils/config\";\n\n/**\n * Initialize and validate OpenAI configuration\n */\nexport function initializeOpenAI(_config: any, runtime: IAgentRuntime) {\n  // Run validation in the background without blocking initialization\n  void (async () => {\n    try {\n      if (!getApiKey(runtime) && !isBrowser()) {\n        logger.warn(\n          \"OPENAI_API_KEY is not set in environment - OpenAI functionality will be limited\",\n        );\n        return;\n      }\n      try {\n        const baseURL = getBaseURL(runtime);\n        const response = await fetch(`${baseURL}/models`, {\n          headers: getAuthHeader(runtime),\n        });\n        if (!response.ok) {\n          logger.warn(\n            `OpenAI API key validation failed: ${response.statusText}`,\n          );\n          logger.warn(\n            \"OpenAI functionality will be limited until a valid API key is provided\",\n          );\n        } else {\n          logger.log(\"OpenAI API key validated successfully\");\n        }\n      } catch (fetchError: unknown) {\n        const message =\n          fetchError instanceof Error ? fetchError.message : String(fetchError);\n        logger.warn(`Error validating OpenAI API key: ${message}`);\n        logger.warn(\n          \"OpenAI functionality will be limited until a valid API key is provided\",\n        );\n      }\n    } catch (error: unknown) {\n      const message =\n        (error as { errors?: Array<{ message: string }> })?.errors\n          ?.map((e) => e.message)\n          .join(\", \") ||\n        (error instanceof Error ? error.message : String(error));\n      logger.warn(\n        `OpenAI plugin configuration issue: ${message} - You need to configure the OPENAI_API_KEY in your environment variables`,\n      );\n    }\n  })();\n}\n",
    "import type { IAgentRuntime } from \"@elizaos/core\";\nimport { logger } from \"@elizaos/core\";\n\n/**\n * Retrieves a configuration setting from the runtime, falling back to environment variables or a default value if not found.\n *\n * @param key - The name of the setting to retrieve.\n * @param defaultValue - The value to return if the setting is not found in the runtime or environment.\n * @returns The resolved setting value, or {@link defaultValue} if not found.\n */\nexport function getSetting(\n  runtime: IAgentRuntime,\n  key: string,\n  defaultValue?: string,\n): string | undefined {\n  return runtime.getSetting(key) ?? process.env[key] ?? defaultValue;\n}\n\nexport function isBrowser(): boolean {\n  return (\n    typeof globalThis !== \"undefined\" &&\n    \"document\" in (globalThis as any) &&\n    typeof (globalThis as any).document !== \"undefined\"\n  );\n}\n\n/**\n * Determines whether we're running in a browser with a server-hosted proxy configured.\n * In this mode, we do not require a real API key on the client and rely on the proxy to inject it.\n */\nexport function isProxyMode(runtime: IAgentRuntime): boolean {\n  return isBrowser() && !!getSetting(runtime, \"OPENAI_BROWSER_BASE_URL\");\n}\n\nexport function getAuthHeader(\n  runtime: IAgentRuntime,\n  forEmbedding = false,\n): Record<string, string> {\n  if (isBrowser()) return {};\n  const key = forEmbedding ? getEmbeddingApiKey(runtime) : getApiKey(runtime);\n  return key ? { Authorization: `Bearer ${key}` } : {};\n}\n\n/**\n * Retrieves the OpenAI API base URL from runtime settings, environment variables, or defaults, using provider-aware resolution.\n *\n * @returns The resolved base URL for OpenAI API requests.\n */\nexport function getBaseURL(runtime: IAgentRuntime): string {\n  const browserURL = getSetting(runtime, \"OPENAI_BROWSER_BASE_URL\");\n  const baseURL = (\n    isBrowser() && browserURL\n      ? browserURL\n      : getSetting(runtime, \"OPENAI_BASE_URL\", \"https://api.openai.com/v1\")\n  ) as string;\n  logger.debug(`[OpenAI] Default base URL: ${baseURL}`);\n  return baseURL;\n}\n\n/**\n * Retrieves the OpenAI API base URL for embeddings, falling back to the general base URL.\n *\n * @returns The resolved base URL for OpenAI embedding requests.\n */\nexport function getEmbeddingBaseURL(runtime: IAgentRuntime): string {\n  const embeddingURL = isBrowser()\n    ? getSetting(runtime, \"OPENAI_BROWSER_EMBEDDING_URL\") ||\n      getSetting(runtime, \"OPENAI_BROWSER_BASE_URL\")\n    : getSetting(runtime, \"OPENAI_EMBEDDING_URL\");\n  if (embeddingURL) {\n    logger.debug(`[OpenAI] Using specific embedding base URL: ${embeddingURL}`);\n    return embeddingURL;\n  }\n  logger.debug(\"[OpenAI] Falling back to general base URL for embeddings.\");\n  return getBaseURL(runtime);\n}\n\n/**\n * Helper function to get the API key for OpenAI\n *\n * @param runtime The runtime context\n * @returns The configured API key\n */\nexport function getApiKey(runtime: IAgentRuntime): string | undefined {\n  return getSetting(runtime, \"OPENAI_API_KEY\");\n}\n\n/**\n * Helper function to get the embedding API key for OpenAI, falling back to the general API key if not set.\n *\n * @param runtime The runtime context\n * @returns The configured API key\n */\nexport function getEmbeddingApiKey(runtime: IAgentRuntime): string | undefined {\n  const embeddingApiKey = getSetting(runtime, \"OPENAI_EMBEDDING_API_KEY\");\n  if (embeddingApiKey) {\n    logger.debug(\"[OpenAI] Using specific embedding API key (present)\");\n    return embeddingApiKey;\n  }\n  logger.debug(\"[OpenAI] Falling back to general API key for embeddings.\");\n  return getApiKey(runtime);\n}\n\n/**\n * Helper function to get the small model name with fallbacks\n *\n * @param runtime The runtime context\n * @returns The configured small model name\n */\nexport function getSmallModel(runtime: IAgentRuntime): string {\n  return (\n    getSetting(runtime, \"OPENAI_SMALL_MODEL\") ??\n    getSetting(runtime, \"SMALL_MODEL\", \"gpt-4o-mini\")!\n  );\n}\n\n/**\n * Helper function to get the large model name with fallbacks\n *\n * @param runtime The runtime context\n * @returns The configured large model name\n */\nexport function getLargeModel(runtime: IAgentRuntime): string {\n  return (\n    getSetting(runtime, \"OPENAI_LARGE_MODEL\") ??\n    getSetting(runtime, \"LARGE_MODEL\", \"gpt-4o\")!\n  );\n}\n\n/**\n * Helper function to get the image description model name with fallbacks\n *\n * @param runtime The runtime context\n * @returns The configured image description model name\n */\nexport function getImageDescriptionModel(runtime: IAgentRuntime): string {\n  return getSetting(runtime, \"OPENAI_IMAGE_DESCRIPTION_MODEL\", \"gpt-5-nano\")!;\n}\n\n/**\n * Helper function to get experimental telemetry setting\n *\n * @param runtime The runtime context\n * @returns Whether experimental telemetry is enabled\n */\nexport function getExperimentalTelemetry(runtime: IAgentRuntime): boolean {\n  const setting = getSetting(runtime, \"OPENAI_EXPERIMENTAL_TELEMETRY\", \"false\");\n  // Convert to string and check for truthy values\n  const normalizedSetting = String(setting).toLowerCase();\n  const result = normalizedSetting === \"true\";\n  logger.debug(\n    `[OpenAI] Experimental telemetry in function: \"${setting}\" (type: ${typeof setting}, normalized: \"${normalizedSetting}\", result: ${result})`,\n  );\n  return result;\n}\n",
    "import type {\n  GenerateTextParams,\n  IAgentRuntime,\n  ModelTypeName,\n} from \"@elizaos/core\";\nimport { logger, ModelType } from \"@elizaos/core\";\nimport { generateText } from \"ai\";\nimport { createOpenAIClient } from \"../providers\";\nimport {\n  getSmallModel,\n  getLargeModel,\n  getExperimentalTelemetry,\n} from \"../utils/config\";\nimport { emitModelUsageEvent } from \"../utils/events\";\n\nasync function generateTextByModelType(\n  runtime: IAgentRuntime,\n  params: GenerateTextParams,\n  modelType: ModelTypeName,\n  getModelFn: (runtime: IAgentRuntime) => string,\n): Promise<string> {\n  const openai = createOpenAIClient(runtime);\n  const modelName = getModelFn(runtime);\n  const experimentalTelemetry = getExperimentalTelemetry(runtime);\n\n  logger.log(`[OpenAI] Using ${modelType} model: ${modelName}`);\n  logger.log(params.prompt);\n\n  const {\n    prompt,\n    stopSequences = [],\n    maxTokens = 8192,\n    temperature = 0.7,\n    frequencyPenalty = 0.7,\n    presencePenalty = 0.7,\n  } = params;\n\n  const { text: openaiResponse, usage } = await generateText({\n    model: openai.languageModel(modelName),\n    prompt: prompt,\n    system: runtime.character.system ?? undefined,\n    temperature: temperature,\n    maxOutputTokens: maxTokens,\n    frequencyPenalty: frequencyPenalty,\n    presencePenalty: presencePenalty,\n    stopSequences: stopSequences,\n    experimental_telemetry: {\n      isEnabled: experimentalTelemetry,\n    },\n  });\n\n  if (usage) {\n    emitModelUsageEvent(runtime, modelType, prompt, usage);\n  }\n\n  return openaiResponse;\n}\n\n/**\n * TEXT_SMALL model handler\n */\nexport async function handleTextSmall(\n  runtime: IAgentRuntime,\n  params: GenerateTextParams,\n): Promise<string> {\n  return generateTextByModelType(\n    runtime,\n    params,\n    ModelType.TEXT_SMALL,\n    getSmallModel,\n  );\n}\n\n/**\n * TEXT_LARGE model handler\n */\nexport async function handleTextLarge(\n  runtime: IAgentRuntime,\n  params: GenerateTextParams,\n): Promise<string> {\n  return generateTextByModelType(\n    runtime,\n    params,\n    ModelType.TEXT_LARGE,\n    getLargeModel,\n  );\n}\n",
    "import { createOpenAI } from \"@ai-sdk/openai\";\nimport type { IAgentRuntime } from \"@elizaos/core\";\nimport { getApiKey, getBaseURL, isProxyMode } from \"../utils/config\";\n\n/**\n * Create an OpenAI client with proper configuration\n *\n * @param runtime The runtime context\n * @returns Configured OpenAI client\n */\nexport function createOpenAIClient(runtime: IAgentRuntime) {\n  const baseURL = getBaseURL(runtime);\n  // In proxy mode (browser + proxy base URL), pass a harmless placeholder key.\n  // The server proxy replaces Authorization; no secrets leave the server.\n  const apiKey =\n    getApiKey(runtime) ?? (isProxyMode(runtime) ? \"sk-proxy\" : undefined);\n  return createOpenAI({ apiKey: (apiKey ?? \"\") as string, baseURL });\n}\n",
    "import type { IAgentRuntime, ModelTypeName } from \"@elizaos/core\";\nimport { EventType } from \"@elizaos/core\";\nimport type { LanguageModelUsage } from \"ai\";\n\n/**\n * Emits a model usage event\n * @param runtime The runtime context\n * @param type The model type\n * @param prompt The prompt used\n * @param usage The LLM usage data\n */\nexport function emitModelUsageEvent(\n  runtime: IAgentRuntime,\n  type: ModelTypeName,\n  prompt: string,\n  usage: LanguageModelUsage,\n) {\n  const promptTokens =\n    (\"promptTokens\" in usage\n      ? (usage as { promptTokens?: number }).promptTokens\n      : undefined) ??\n    (\"inputTokens\" in usage\n      ? (usage as { inputTokens?: number }).inputTokens\n      : undefined) ??\n    0;\n  const completionTokens =\n    (\"completionTokens\" in usage\n      ? (usage as { completionTokens?: number }).completionTokens\n      : undefined) ??\n    (\"outputTokens\" in usage\n      ? (usage as { outputTokens?: number }).outputTokens\n      : undefined) ??\n    0;\n  const totalTokens =\n    (\"totalTokens\" in usage\n      ? (usage as { totalTokens?: number }).totalTokens\n      : undefined) ?? promptTokens + completionTokens;\n\n  runtime.emitEvent(EventType.MODEL_USED, {\n    provider: \"openai\",\n    type,\n    prompt,\n    tokens: {\n      prompt: promptTokens,\n      completion: completionTokens,\n      total: totalTokens,\n    },\n  });\n}\n",
    "import type { IAgentRuntime, TextEmbeddingParams } from \"@elizaos/core\";\nimport { logger, ModelType, VECTOR_DIMS } from \"@elizaos/core\";\nimport {\n  getSetting,\n  getEmbeddingBaseURL,\n  getAuthHeader,\n} from \"../utils/config\";\nimport { emitModelUsageEvent } from \"../utils/events\";\n\n/**\n * TEXT_EMBEDDING model handler\n */\nexport async function handleTextEmbedding(\n  runtime: IAgentRuntime,\n  params: TextEmbeddingParams | string | null,\n): Promise<number[]> {\n  const embeddingModelName = getSetting(\n    runtime,\n    \"OPENAI_EMBEDDING_MODEL\",\n    \"text-embedding-3-small\",\n  );\n  const embeddingDimension = Number.parseInt(\n    getSetting(runtime, \"OPENAI_EMBEDDING_DIMENSIONS\", \"1536\") || \"1536\",\n    10,\n  ) as (typeof VECTOR_DIMS)[keyof typeof VECTOR_DIMS];\n\n  if (!Object.values(VECTOR_DIMS).includes(embeddingDimension)) {\n    const errorMsg = `Invalid embedding dimension: ${embeddingDimension}. Must be one of: ${Object.values(VECTOR_DIMS).join(\", \")}`;\n    logger.error(errorMsg);\n    throw new Error(errorMsg);\n  }\n  if (params === null) {\n    logger.debug(\"Creating test embedding for initialization\");\n    const testVector = Array(embeddingDimension).fill(0);\n    testVector[0] = 0.1;\n    return testVector;\n  }\n  let text: string;\n  if (typeof params === \"string\") {\n    text = params;\n  } else if (typeof params === \"object\" && params.text) {\n    text = params.text;\n  } else {\n    const errorMsg = \"Invalid input format for embedding\";\n    logger.warn(errorMsg);\n    const fallbackVector = Array(embeddingDimension).fill(0);\n    fallbackVector[0] = 0.2;\n    return fallbackVector;\n  }\n  if (!text.trim()) {\n    const errorMsg = \"Empty text for embedding\";\n    logger.warn(errorMsg);\n    const fallbackVector = Array(embeddingDimension).fill(0);\n    fallbackVector[0] = 0.3;\n    return fallbackVector;\n  }\n\n  const embeddingBaseURL = getEmbeddingBaseURL(runtime);\n\n  try {\n    const response = await fetch(`${embeddingBaseURL}/embeddings`, {\n      method: \"POST\",\n      headers: {\n        ...getAuthHeader(runtime, true),\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify({\n        model: embeddingModelName,\n        input: text,\n      }),\n    });\n\n    if (!response.ok) {\n      logger.error(\n        `OpenAI API error: ${response.status} - ${response.statusText}`,\n      );\n      throw new Error(\n        `OpenAI API error: ${response.status} - ${response.statusText}`,\n      );\n    }\n\n    const data = (await response.json()) as {\n      data: [{ embedding: number[] }];\n      usage?: { prompt_tokens: number; total_tokens: number };\n    };\n\n    if (!data?.data?.[0]?.embedding) {\n      logger.error(\"API returned invalid structure\");\n      throw new Error(\"API returned invalid structure\");\n    }\n\n    const embedding = data.data[0].embedding;\n\n    if (!Array.isArray(embedding) || embedding.length !== embeddingDimension) {\n      const errorMsg = `Embedding length ${embedding?.length ?? 0} does not match configured dimension ${embeddingDimension}`;\n      logger.error(errorMsg);\n      const fallbackVector = Array(embeddingDimension).fill(0);\n      fallbackVector[0] = 0.4;\n      return fallbackVector;\n    }\n\n    if (data.usage) {\n      const usage = {\n        inputTokens: data.usage.prompt_tokens,\n        outputTokens: 0,\n        totalTokens: data.usage.total_tokens,\n      };\n\n      emitModelUsageEvent(runtime, ModelType.TEXT_EMBEDDING, text, usage);\n    }\n\n    logger.log(`Got valid embedding with length ${embedding.length}`);\n    return embedding;\n  } catch (error: unknown) {\n    const message = error instanceof Error ? error.message : String(error);\n    logger.error(`Error generating embedding: ${message}`);\n    throw error instanceof Error ? error : new Error(message);\n  }\n}\n",
    "import type { IAgentRuntime, ImageDescriptionParams } from \"@elizaos/core\";\nimport { logger, ModelType } from \"@elizaos/core\";\nimport type {\n  OpenAIImageDescriptionResult,\n  OpenAIImageGenerationResult,\n} from \"../types\";\nimport {\n  getSetting,\n  getBaseURL,\n  getAuthHeader,\n  getImageDescriptionModel,\n} from \"../utils/config\";\nimport { emitModelUsageEvent } from \"../utils/events\";\n\n/**\n * IMAGE generation model handler\n */\nexport async function handleImageGeneration(\n  runtime: IAgentRuntime,\n  params: {\n    prompt: string;\n    n?: number;\n    size?: string;\n  },\n): Promise<OpenAIImageGenerationResult> {\n  const n = params.n || 1;\n  const size = params.size || \"1024x1024\";\n  const prompt = params.prompt;\n  const modelName = getSetting(\n    runtime,\n    \"OPENAI_IMAGE_MODEL\",\n    \"gpt-image-1\",\n  ) as string;\n  logger.log(`[OpenAI] Using IMAGE model: ${modelName}`);\n\n  const baseURL = getBaseURL(runtime);\n\n  try {\n    const response = await fetch(`${baseURL}/images/generations`, {\n      method: \"POST\",\n      headers: {\n        ...getAuthHeader(runtime),\n        \"Content-Type\": \"application/json\",\n      },\n      body: JSON.stringify({\n        model: modelName,\n        prompt: prompt,\n        n: n,\n        size: size,\n      }),\n    });\n\n    if (!response.ok) {\n      throw new Error(`Failed to generate image: ${response.statusText}`);\n    }\n\n    const data = await response.json();\n    const typedData = data as { data: { url: string }[] };\n\n    return typedData;\n  } catch (error: unknown) {\n    const message = error instanceof Error ? error.message : String(error);\n    throw error;\n  }\n}\n\n/**\n * IMAGE_DESCRIPTION model handler\n */\nexport async function handleImageDescription(\n  runtime: IAgentRuntime,\n  params: ImageDescriptionParams | string,\n): Promise<OpenAIImageDescriptionResult | string> {\n  let imageUrl: string;\n  let promptText: string | undefined;\n  const modelName = getImageDescriptionModel(runtime);\n  logger.log(`[OpenAI] Using IMAGE_DESCRIPTION model: ${modelName}`);\n  const maxTokens = Number.parseInt(\n    getSetting(runtime, \"OPENAI_IMAGE_DESCRIPTION_MAX_TOKENS\", \"8192\") ||\n      \"8192\",\n    10,\n  );\n\n  const DEFAULT_PROMPT =\n    \"Please analyze this image and provide a title and detailed description.\";\n\n  if (typeof params === \"string\") {\n    imageUrl = params;\n    promptText = DEFAULT_PROMPT;\n  } else {\n    imageUrl = params.imageUrl;\n    promptText = params.prompt || DEFAULT_PROMPT;\n  }\n\n  const messages = [\n    {\n      role: \"user\",\n      content: [\n        { type: \"text\", text: promptText },\n        { type: \"image_url\", image_url: { url: imageUrl } },\n      ],\n    },\n  ];\n\n  const baseURL = getBaseURL(runtime);\n\n  try {\n    const requestBody: Record<string, any> = {\n      model: modelName,\n      messages: messages,\n      max_tokens: maxTokens,\n    };\n\n    const response = await fetch(`${baseURL}/chat/completions`, {\n      method: \"POST\",\n      headers: {\n        \"Content-Type\": \"application/json\",\n        ...getAuthHeader(runtime),\n      },\n      body: JSON.stringify(requestBody),\n    });\n\n    if (!response.ok) {\n      throw new Error(`OpenAI API error: ${response.status}`);\n    }\n\n    const result: unknown = await response.json();\n\n    type OpenAIResponseType = {\n      choices?: Array<{\n        message?: { content?: string };\n        finish_reason?: string;\n      }>;\n      usage?: {\n        prompt_tokens: number;\n        completion_tokens: number;\n        total_tokens: number;\n      };\n    };\n\n    const typedResult = result as OpenAIResponseType;\n    const content = typedResult.choices?.[0]?.message?.content;\n\n    if (typedResult.usage) {\n      emitModelUsageEvent(\n        runtime,\n        ModelType.IMAGE_DESCRIPTION,\n        typeof params === \"string\" ? params : params.prompt || \"\",\n        {\n          inputTokens: typedResult.usage.prompt_tokens,\n          outputTokens: typedResult.usage.completion_tokens,\n          totalTokens: typedResult.usage.total_tokens,\n        },\n      );\n    }\n\n    if (!content) {\n      return {\n        title: \"Failed to analyze image\",\n        description: \"No response from API\",\n      };\n    }\n\n    // Check if a custom prompt was provided\n    const isCustomPrompt =\n      typeof params === \"object\" &&\n      Boolean(params.prompt) &&\n      params.prompt !== DEFAULT_PROMPT;\n\n    // If custom prompt is used, return the raw content\n    if (isCustomPrompt) {\n      return content;\n    }\n\n    // Otherwise, maintain backwards compatibility with object return\n    const titleMatch = content.match(/title[:\\s]+(.+?)(?:\\n|$)/i);\n    const title = titleMatch?.[1]?.trim();\n    if (!title) {\n      logger.warn(\"Could not extract title from image description response\");\n    }\n    const finalTitle = title || \"Image Analysis\";\n    const description = content.replace(/title[:\\s]+(.+?)(?:\\n|$)/i, \"\").trim();\n\n    const processedResult = { title: finalTitle, description };\n    return processedResult;\n  } catch (error: unknown) {\n    const message = error instanceof Error ? error.message : String(error);\n    logger.error(`Error analyzing image: ${message}`);\n    return {\n      title: \"Failed to analyze image\",\n      description: `Error: ${message}`,\n    };\n  }\n}\n",
    "import type { IAgentRuntime } from \"@elizaos/core\";\nimport { logger } from \"@elizaos/core\";\nimport type {\n  OpenAITranscriptionParams,\n  OpenAITextToSpeechParams,\n} from \"../types\";\nimport {\n  getSetting,\n  getBaseURL,\n  getAuthHeader,\n  isBrowser,\n} from \"../utils/config\";\nimport { detectAudioMimeType, webStreamToNodeStream } from \"../utils/audio\";\n\n/**\n * Helper function for text-to-speech\n */\nasync function fetchTextToSpeech(\n  runtime: IAgentRuntime,\n  options: OpenAITextToSpeechParams,\n) {\n  const defaultModel = getSetting(\n    runtime,\n    \"OPENAI_TTS_MODEL\",\n    \"gpt-4o-mini-tts\",\n  );\n  const defaultVoice = getSetting(runtime, \"OPENAI_TTS_VOICE\", \"nova\");\n  const defaultInstructions = getSetting(\n    runtime,\n    \"OPENAI_TTS_INSTRUCTIONS\",\n    \"\",\n  );\n  const baseURL = getBaseURL(runtime);\n\n  const model = options.model || (defaultModel as string);\n  const voice = options.voice || (defaultVoice as string);\n  const instructions = options.instructions ?? (defaultInstructions as string);\n  const format = options.format || \"mp3\";\n\n  try {\n    const res = await fetch(`${baseURL}/audio/speech`, {\n      method: \"POST\",\n      headers: {\n        ...getAuthHeader(runtime),\n        \"Content-Type\": \"application/json\",\n        // Hint desired audio format in Accept when possible\n        ...(format === \"mp3\" ? { Accept: \"audio/mpeg\" } : {}),\n      },\n      body: JSON.stringify({\n        model,\n        voice,\n        input: options.text,\n        format,\n        ...(instructions && { instructions }),\n      }),\n    });\n\n    if (!res.ok) {\n      const err = await res.text();\n      throw new Error(`OpenAI TTS error ${res.status}: ${err}`);\n    }\n\n    // Ensure response body exists\n    if (!res.body) {\n      throw new Error(\"OpenAI TTS response body is null\");\n    }\n\n    // In Node.js, convert Web ReadableStream to Node.js Readable\n    // In browser, return the Web ReadableStream directly\n    if (!isBrowser()) {\n      return await webStreamToNodeStream(res.body);\n    }\n\n    return res.body;\n  } catch (err: unknown) {\n    const message = err instanceof Error ? err.message : String(err);\n    throw new Error(`Failed to fetch speech from OpenAI TTS: ${message}`);\n  }\n}\n\n/**\n * TRANSCRIPTION model handler\n */\nexport async function handleTranscription(\n  runtime: IAgentRuntime,\n  input: Blob | File | Buffer | OpenAITranscriptionParams,\n): Promise<string> {\n  let modelName = getSetting(\n    runtime,\n    \"OPENAI_TRANSCRIPTION_MODEL\",\n    \"gpt-4o-mini-transcribe\",\n  );\n  logger.log(`[OpenAI] Using TRANSCRIPTION model: ${modelName}`);\n\n  const baseURL = getBaseURL(runtime);\n\n  // Support Blob/File/Buffer directly, or an object with { audio: Blob/File/Buffer, ...options }\n  let blob: Blob;\n  let extraParams: OpenAITranscriptionParams | null = null;\n\n  if (input instanceof Blob || input instanceof File) {\n    blob = input as Blob;\n  } else if (Buffer.isBuffer(input)) {\n    // Convert Buffer to Blob for Node.js environments\n    // Auto-detect MIME type from buffer content\n    const detectedMimeType = detectAudioMimeType(input);\n    logger.debug(`Auto-detected audio MIME type: ${detectedMimeType}`);\n    // Create a new Uint8Array from the Buffer to ensure type compatibility\n    const uint8Array = new Uint8Array(input);\n    blob = new Blob([uint8Array], { type: detectedMimeType });\n  } else if (\n    typeof input === \"object\" &&\n    input !== null &&\n    (input as any).audio != null\n  ) {\n    const params = input as any;\n    if (\n      !(params.audio instanceof Blob) &&\n      !(params.audio instanceof File) &&\n      !Buffer.isBuffer(params.audio)\n    ) {\n      throw new Error(\n        \"TRANSCRIPTION param 'audio' must be a Blob/File/Buffer.\",\n      );\n    }\n    // Convert Buffer to Blob if needed\n    if (Buffer.isBuffer(params.audio)) {\n      // Use provided mimeType or auto-detect from buffer\n      let mimeType = params.mimeType;\n      if (!mimeType) {\n        mimeType = detectAudioMimeType(params.audio);\n        logger.debug(`Auto-detected audio MIME type: ${mimeType}`);\n      } else {\n        logger.debug(`Using provided MIME type: ${mimeType}`);\n      }\n      // Create a new Uint8Array from the Buffer to ensure type compatibility\n      const uint8Array = new Uint8Array(params.audio);\n      blob = new Blob([uint8Array], { type: mimeType });\n    } else {\n      blob = params.audio as Blob;\n    }\n    extraParams = params as OpenAITranscriptionParams;\n    if (typeof params.model === \"string\" && params.model) {\n      modelName = params.model;\n    }\n  } else {\n    throw new Error(\n      \"TRANSCRIPTION expects a Blob/File/Buffer or an object { audio: Blob/File/Buffer, mimeType?, language?, response_format?, timestampGranularities?, prompt?, temperature?, model? }\",\n    );\n  }\n\n  const mime = (blob as File).type || \"audio/webm\";\n  const filename =\n    (blob as File).name ||\n    (mime.includes(\"mp3\") || mime.includes(\"mpeg\")\n      ? \"recording.mp3\"\n      : mime.includes(\"ogg\")\n        ? \"recording.ogg\"\n        : mime.includes(\"wav\")\n          ? \"recording.wav\"\n          : mime.includes(\"webm\")\n            ? \"recording.webm\"\n            : \"recording.bin\");\n\n  const formData = new FormData();\n  formData.append(\"file\", blob, filename);\n  formData.append(\"model\", String(modelName));\n  if (extraParams) {\n    if (typeof extraParams.language === \"string\") {\n      formData.append(\"language\", String(extraParams.language));\n    }\n    if (typeof extraParams.response_format === \"string\") {\n      formData.append(\"response_format\", String(extraParams.response_format));\n    }\n    if (typeof extraParams.prompt === \"string\") {\n      formData.append(\"prompt\", String(extraParams.prompt));\n    }\n    if (typeof extraParams.temperature === \"number\") {\n      formData.append(\"temperature\", String(extraParams.temperature));\n    }\n    if (Array.isArray(extraParams.timestampGranularities)) {\n      for (const g of extraParams.timestampGranularities) {\n        formData.append(\"timestamp_granularities[]\", String(g));\n      }\n    }\n  }\n\n  try {\n    const response = await fetch(`${baseURL}/audio/transcriptions`, {\n      method: \"POST\",\n      headers: {\n        ...getAuthHeader(runtime),\n      },\n      body: formData,\n    });\n\n    if (!response.ok) {\n      throw new Error(\n        `Failed to transcribe audio: ${response.status} ${response.statusText}`,\n      );\n    }\n\n    const data = (await response.json()) as { text: string };\n    return data.text || \"\";\n  } catch (error: unknown) {\n    const message = error instanceof Error ? error.message : String(error);\n    logger.error(`TRANSCRIPTION error: ${message}`);\n    throw error;\n  }\n}\n\n/**\n * TEXT_TO_SPEECH model handler\n */\nexport async function handleTextToSpeech(\n  runtime: IAgentRuntime,\n  input: string | OpenAITextToSpeechParams,\n): Promise<ReadableStream<Uint8Array> | NodeJS.ReadableStream> {\n  // Normalize input into options with per-call overrides\n  const options: OpenAITextToSpeechParams =\n    typeof input === \"string\"\n      ? { text: input }\n      : (input as OpenAITextToSpeechParams);\n\n  const resolvedModel =\n    options.model ||\n    (getSetting(runtime, \"OPENAI_TTS_MODEL\", \"gpt-4o-mini-tts\") as string);\n  logger.log(`[OpenAI] Using TEXT_TO_SPEECH model: ${resolvedModel}`);\n  try {\n    const speechStream = await fetchTextToSpeech(runtime, options);\n    return speechStream;\n  } catch (error: unknown) {\n    const message = error instanceof Error ? error.message : String(error);\n    logger.error(`Error in TEXT_TO_SPEECH: ${message}`);\n    throw error;\n  }\n}\n",
    "import { logger } from \"@elizaos/core\";\n\nconst MAGIC_BYTES = {\n  WAV: {\n    HEADER: [0x52, 0x49, 0x46, 0x46] as const,\n    IDENTIFIER: [0x57, 0x41, 0x56, 0x45] as const,\n  },\n  MP3_ID3: [0x49, 0x44, 0x33] as const,\n  OGG: [0x4f, 0x67, 0x67, 0x53] as const,\n  FLAC: [0x66, 0x4c, 0x61, 0x43] as const,\n  FTYP: [0x66, 0x74, 0x79, 0x70] as const, // at offset 4 for mp4/m4a\n  WEBM_EBML: [0x1a, 0x45, 0xdf, 0xa3] as const,\n} as const;\n\nfunction matchBytes(\n  buffer: Buffer,\n  offset: number,\n  bytes: readonly number[],\n): boolean {\n  for (let i = 0; i < bytes.length; i++) {\n    if (buffer[offset + i] !== bytes[i]!) return false;\n  }\n  return true;\n}\n\n/**\n * Detects audio MIME type from buffer by checking magic bytes (file signature)\n * @param buffer The audio buffer to analyze\n * @returns The detected MIME type or 'application/octet-stream' if unknown\n */\nexport function detectAudioMimeType(buffer: Buffer): string {\n  if (buffer.length < 12) {\n    return \"application/octet-stream\";\n  }\n\n  // Check magic bytes for common audio formats\n  // WAV: \"RIFF\" + size + \"WAVE\"\n  if (\n    matchBytes(buffer, 0, MAGIC_BYTES.WAV.HEADER) &&\n    matchBytes(buffer, 8, MAGIC_BYTES.WAV.IDENTIFIER)\n  ) {\n    return \"audio/wav\";\n  }\n\n  // MP3: ID3 tag or MPEG frame sync\n  if (\n    matchBytes(buffer, 0, MAGIC_BYTES.MP3_ID3) || // ID3\n    (buffer[0] === 0xff && (buffer[1] & 0xe0) === 0xe0) // MPEG sync\n  ) {\n    return \"audio/mpeg\";\n  }\n\n  // OGG: \"OggS\"\n  if (matchBytes(buffer, 0, MAGIC_BYTES.OGG)) {\n    return \"audio/ogg\";\n  }\n\n  // FLAC: \"fLaC\"\n  if (matchBytes(buffer, 0, MAGIC_BYTES.FLAC)) {\n    return \"audio/flac\";\n  }\n\n  // M4A/MP4: \"ftyp\" at offset 4\n  if (matchBytes(buffer, 4, MAGIC_BYTES.FTYP)) {\n    return \"audio/mp4\";\n  }\n\n  // WebM: EBML header\n  if (matchBytes(buffer, 0, MAGIC_BYTES.WEBM_EBML)) {\n    return \"audio/webm\";\n  }\n\n  // Unknown format - let API try to detect\n  logger.warn(\n    \"Could not detect audio format from buffer, using generic binary type\",\n  );\n  return \"application/octet-stream\";\n}\n\n/**\n * Converts a Web ReadableStream to a Node.js Readable stream\n * Handles both browser and Node.js environments\n * Uses dynamic import to avoid bundling node:stream in browser builds\n */\nexport async function webStreamToNodeStream(\n  webStream: ReadableStream<Uint8Array>,\n) {\n  try {\n    // Dynamic import to avoid browser bundling issues\n    const { Readable } = await import(\"node:stream\");\n    const reader = webStream.getReader();\n\n    return new Readable({\n      async read() {\n        try {\n          const { done, value } = await reader.read();\n          if (done) {\n            this.push(null);\n          } else {\n            // Push the Uint8Array directly; Node.js Readable can handle it\n            this.push(value);\n          }\n        } catch (error) {\n          this.destroy(error as Error);\n        }\n      },\n      destroy(error, callback) {\n        reader.cancel().finally(() => callback(error));\n      },\n    });\n  } catch (error) {\n    const message = error instanceof Error ? error.message : String(error);\n    logger.error(`Failed to load node:stream module: ${message}`);\n    throw new Error(\n      `Cannot convert stream: node:stream module unavailable. This feature requires a Node.js environment.`,\n    );\n  }\n}\n",
    "import type {\n  IAgentRuntime,\n  ObjectGenerationParams,\n  ModelTypeName,\n} from \"@elizaos/core\";\nimport { logger, ModelType } from \"@elizaos/core\";\nimport { generateObject, type JSONValue } from \"ai\";\nimport { createOpenAIClient } from \"../providers\";\nimport { getSmallModel, getLargeModel } from \"../utils/config\";\nimport { emitModelUsageEvent } from \"../utils/events\";\nimport { getJsonRepairFunction } from \"../utils/json\";\n\n/**\n * Helper function to generate objects using specified model type\n */\nasync function generateObjectByModelType(\n  runtime: IAgentRuntime,\n  params: ObjectGenerationParams,\n  modelType: ModelTypeName,\n  getModelFn: (runtime: IAgentRuntime) => string,\n): Promise<JSONValue> {\n  const openai = createOpenAIClient(runtime);\n  const modelName = getModelFn(runtime);\n  logger.log(`[OpenAI] Using ${modelType} model: ${modelName}`);\n  const temperature = params.temperature ?? 0;\n  const schemaPresent = !!params.schema;\n\n  if (schemaPresent) {\n    logger.warn(\n      `Schema provided but ignored: OpenAI object generation currently uses output=no-schema. The schema parameter has no effect.`,\n    );\n  }\n\n  try {\n    const { object, usage } = await generateObject({\n      model: openai.languageModel(modelName),\n      output: \"no-schema\",\n      prompt: params.prompt,\n      temperature: temperature,\n      experimental_repairText: getJsonRepairFunction(),\n    });\n\n    if (usage) {\n      emitModelUsageEvent(runtime, modelType, params.prompt, usage);\n    }\n    return object;\n  } catch (error: unknown) {\n    const message = error instanceof Error ? error.message : String(error);\n    logger.error(`[generateObject] Error: ${message}`);\n    throw error;\n  }\n}\n\n/**\n * OBJECT_SMALL model handler\n */\nexport async function handleObjectSmall(\n  runtime: IAgentRuntime,\n  params: ObjectGenerationParams,\n): Promise<JSONValue> {\n  return generateObjectByModelType(\n    runtime,\n    params,\n    ModelType.OBJECT_SMALL,\n    getSmallModel,\n  );\n}\n\n/**\n * OBJECT_LARGE model handler\n */\nexport async function handleObjectLarge(\n  runtime: IAgentRuntime,\n  params: ObjectGenerationParams,\n): Promise<JSONValue> {\n  return generateObjectByModelType(\n    runtime,\n    params,\n    ModelType.OBJECT_LARGE,\n    getLargeModel,\n  );\n}\n",
    "import { logger } from \"@elizaos/core\";\nimport { JSONParseError } from \"ai\";\n\n/**\n * Returns a function to repair JSON text\n */\nexport function getJsonRepairFunction(): (params: {\n  text: string;\n  error: unknown;\n}) => Promise<string | null> {\n  return async ({ text, error }: { text: string; error: unknown }) => {\n    try {\n      if (error instanceof JSONParseError) {\n        const cleanedText = text.replace(/```json\\n|\\n```|```/g, \"\");\n        JSON.parse(cleanedText);\n        return cleanedText;\n      }\n      return null;\n    } catch (jsonError: unknown) {\n      const message =\n        jsonError instanceof Error ? jsonError.message : String(jsonError);\n      logger.warn(`Failed to repair JSON text: ${message}`);\n      return null;\n    }\n  };\n}\n",
    "import type {\n  IAgentRuntime,\n  TokenizeTextParams,\n  DetokenizeTextParams,\n} from \"@elizaos/core\";\nimport { ModelType } from \"@elizaos/core\";\nimport { tokenizeText, detokenizeText } from \"../utils/tokenization\";\n\n/**\n * TEXT_TOKENIZER_ENCODE model handler\n */\nexport async function handleTokenizerEncode(\n  runtime: IAgentRuntime,\n  { prompt, modelType = ModelType.TEXT_LARGE }: TokenizeTextParams,\n): Promise<number[]> {\n  return await tokenizeText(runtime, modelType, prompt);\n}\n\n/**\n * TEXT_TOKENIZER_DECODE model handler\n */\nexport async function handleTokenizerDecode(\n  runtime: IAgentRuntime,\n  { tokens, modelType = ModelType.TEXT_LARGE }: DetokenizeTextParams,\n): Promise<string> {\n  return await detokenizeText(runtime, modelType, tokens);\n}\n",
    "import type { IAgentRuntime, ModelTypeName } from \"@elizaos/core\";\nimport { ModelType } from \"@elizaos/core\";\nimport { encodingForModel, getEncoding, type TiktokenModel, type TiktokenEncoding } from \"js-tiktoken\";\nimport { getLargeModel, getSmallModel } from \"./config\";\n\nfunction resolveTokenizerEncoding(\n  modelName: string,\n): ReturnType<typeof encodingForModel> {\n  const normalized = modelName.toLowerCase();\n  const fallbackEncoding: TiktokenEncoding = normalized.includes(\"4o\")\n    ? \"o200k_base\"\n    : \"cl100k_base\";\n\n  try {\n    return encodingForModel(modelName as TiktokenModel);\n  } catch (error: unknown) {\n    // Use getEncoding for the fallback encoding names\n    return getEncoding(fallbackEncoding);\n  }\n}\n\n/**\n * Asynchronously tokenizes the given text based on the specified model and prompt.\n *\n * @param {ModelTypeName} model - The type of model to use for tokenization.\n * @param {string} prompt - The text prompt to tokenize.\n * @returns {number[]} - An array of tokens representing the encoded prompt.\n */\nexport async function tokenizeText(\n  runtime: IAgentRuntime,\n  model: ModelTypeName,\n  prompt: string,\n) {\n  const modelName =\n    model === ModelType.TEXT_SMALL\n      ? getSmallModel(runtime)\n      : getLargeModel(runtime);\n  const tokens = resolveTokenizerEncoding(modelName).encode(prompt);\n  return tokens;\n}\n\n/**\n * Detokenize a sequence of tokens back into text using the specified model.\n *\n * @param {ModelTypeName} model - The type of model to use for detokenization.\n * @param {number[]} tokens - The sequence of tokens to detokenize.\n * @returns {string} The detokenized text.\n */\nexport async function detokenizeText(\n  runtime: IAgentRuntime,\n  model: ModelTypeName,\n  tokens: number[],\n) {\n  const modelName =\n    model === ModelType.TEXT_SMALL\n      ? getSmallModel(runtime)\n      : getLargeModel(runtime);\n  return resolveTokenizerEncoding(modelName).decode(tokens);\n}\n"
  ],
  "mappings": ";;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAUkC,IAAlC;;;ACV2C,IAA3C;;;ACCuB,IAAvB;AASO,SAAS,UAAU,CACxB,SACA,KACA,cACoB;AAAA,EACpB,OAAO,QAAQ,WAAW,GAAG,KAAK,QAAQ,IAAI,QAAQ;AAAA;AAGjD,SAAS,SAAS,GAAY;AAAA,EACnC,OACE,OAAO,eAAe,eACtB,cAAe,cACf,OAAQ,WAAmB,aAAa;AAAA;AAQrC,SAAS,WAAW,CAAC,SAAiC;AAAA,EAC3D,OAAO,UAAU,KAAK,CAAC,CAAC,WAAW,SAAS,yBAAyB;AAAA;AAGhE,SAAS,aAAa,CAC3B,SACA,eAAe,OACS;AAAA,EACxB,IAAI,UAAU;AAAA,IAAG,OAAO,CAAC;AAAA,EACzB,MAAM,MAAM,eAAe,mBAAmB,OAAO,IAAI,UAAU,OAAO;AAAA,EAC1E,OAAO,MAAM,EAAE,eAAe,UAAU,MAAM,IAAI,CAAC;AAAA;AAQ9C,SAAS,UAAU,CAAC,SAAgC;AAAA,EACzD,MAAM,aAAa,WAAW,SAAS,yBAAyB;AAAA,EAChE,MAAM,UACJ,UAAU,KAAK,aACX,aACA,WAAW,SAAS,mBAAmB,2BAA2B;AAAA,EAExE,mBAAO,MAAM,8BAA8B,SAAS;AAAA,EACpD,OAAO;AAAA;AAQF,SAAS,mBAAmB,CAAC,SAAgC;AAAA,EAClE,MAAM,eAAe,UAAU,IAC3B,WAAW,SAAS,8BAA8B,KAClD,WAAW,SAAS,yBAAyB,IAC7C,WAAW,SAAS,sBAAsB;AAAA,EAC9C,IAAI,cAAc;AAAA,IAChB,mBAAO,MAAM,+CAA+C,cAAc;AAAA,IAC1E,OAAO;AAAA,EACT;AAAA,EACA,mBAAO,MAAM,2DAA2D;AAAA,EACxE,OAAO,WAAW,OAAO;AAAA;AASpB,SAAS,SAAS,CAAC,SAA4C;AAAA,EACpE,OAAO,WAAW,SAAS,gBAAgB;AAAA;AAStC,SAAS,kBAAkB,CAAC,SAA4C;AAAA,EAC7E,MAAM,kBAAkB,WAAW,SAAS,0BAA0B;AAAA,EACtE,IAAI,iBAAiB;AAAA,IACnB,mBAAO,MAAM,qDAAqD;AAAA,IAClE,OAAO;AAAA,EACT;AAAA,EACA,mBAAO,MAAM,0DAA0D;AAAA,EACvE,OAAO,UAAU,OAAO;AAAA;AASnB,SAAS,aAAa,CAAC,SAAgC;AAAA,EAC5D,OACE,WAAW,SAAS,oBAAoB,KACxC,WAAW,SAAS,eAAe,aAAa;AAAA;AAU7C,SAAS,aAAa,CAAC,SAAgC;AAAA,EAC5D,OACE,WAAW,SAAS,oBAAoB,KACxC,WAAW,SAAS,eAAe,QAAQ;AAAA;AAUxC,SAAS,wBAAwB,CAAC,SAAgC;AAAA,EACvE,OAAO,WAAW,SAAS,kCAAkC,YAAY;AAAA;AASpE,SAAS,wBAAwB,CAAC,SAAiC;AAAA,EACxE,MAAM,UAAU,WAAW,SAAS,iCAAiC,OAAO;AAAA,EAE5E,MAAM,oBAAoB,OAAO,OAAO,EAAE,YAAY;AAAA,EACtD,MAAM,SAAS,sBAAsB;AAAA,EACrC,mBAAO,MACL,iDAAiD,mBAAmB,OAAO,yBAAyB,+BAA+B,SACrI;AAAA,EACA,OAAO;AAAA;;;AD9IF,SAAS,gBAAgB,CAAC,SAAc,SAAwB;AAAA,GAE/D,YAAY;AAAA,IAChB,IAAI;AAAA,MACF,IAAI,CAAC,UAAU,OAAO,KAAK,CAAC,UAAU,GAAG;AAAA,QACvC,oBAAO,KACL,iFACF;AAAA,QACA;AAAA,MACF;AAAA,MACA,IAAI;AAAA,QACF,MAAM,UAAU,WAAW,OAAO;AAAA,QAClC,MAAM,WAAW,MAAM,MAAM,GAAG,kBAAkB;AAAA,UAChD,SAAS,cAAc,OAAO;AAAA,QAChC,CAAC;AAAA,QACD,IAAI,CAAC,SAAS,IAAI;AAAA,UAChB,oBAAO,KACL,qCAAqC,SAAS,YAChD;AAAA,UACA,oBAAO,KACL,wEACF;AAAA,QACF,EAAO;AAAA,UACL,oBAAO,IAAI,uCAAuC;AAAA;AAAA,QAEpD,OAAO,YAAqB;AAAA,QAC5B,MAAM,UACJ,sBAAsB,QAAQ,WAAW,UAAU,OAAO,UAAU;AAAA,QACtE,oBAAO,KAAK,oCAAoC,SAAS;AAAA,QACzD,oBAAO,KACL,wEACF;AAAA;AAAA,MAEF,OAAO,OAAgB;AAAA,MACvB,MAAM,UACH,OAAmD,QAChD,IAAI,CAAC,MAAM,EAAE,OAAO,EACrB,KAAK,IAAI,MACX,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,MACxD,oBAAO,KACL,sCAAsC,kFACxC;AAAA;AAAA,KAED;AAAA;;;AEjD6B,IAAlC;AAC6B,IAA7B;;;ACN6B,IAA7B;AAUO,SAAS,kBAAkB,CAAC,SAAwB;AAAA,EACzD,MAAM,UAAU,WAAW,OAAO;AAAA,EAGlC,MAAM,SACJ,UAAU,OAAO,MAAM,YAAY,OAAO,IAAI,aAAa;AAAA,EAC7D,OAAO,2BAAa,EAAE,QAAS,UAAU,IAAe,QAAQ,CAAC;AAAA;;;ACfzC,IAA1B;AAUO,SAAS,mBAAmB,CACjC,SACA,MACA,QACA,OACA;AAAA,EACA,MAAM,gBACH,kBAAkB,QACd,MAAoC,eACrC,eACH,iBAAiB,QACb,MAAmC,cACpC,cACJ;AAAA,EACF,MAAM,oBACH,sBAAsB,QAClB,MAAwC,mBACzC,eACH,kBAAkB,QACd,MAAoC,eACrC,cACJ;AAAA,EACF,MAAM,eACH,iBAAiB,QACb,MAAmC,cACpC,cAAc,eAAe;AAAA,EAEnC,QAAQ,UAAU,uBAAU,YAAY;AAAA,IACtC,UAAU;AAAA,IACV;AAAA,IACA;AAAA,IACA,QAAQ;AAAA,MACN,QAAQ;AAAA,MACR,YAAY;AAAA,MACZ,OAAO;AAAA,IACT;AAAA,EACF,CAAC;AAAA;;;AFhCH,eAAe,uBAAuB,CACpC,SACA,QACA,WACA,YACiB;AAAA,EACjB,MAAM,SAAS,mBAAmB,OAAO;AAAA,EACzC,MAAM,YAAY,WAAW,OAAO;AAAA,EACpC,MAAM,wBAAwB,yBAAyB,OAAO;AAAA,EAE9D,oBAAO,IAAI,kBAAkB,oBAAoB,WAAW;AAAA,EAC5D,oBAAO,IAAI,OAAO,MAAM;AAAA,EAExB;AAAA,IACE;AAAA,IACA,gBAAgB,CAAC;AAAA,IACjB,YAAY;AAAA,IACZ,cAAc;AAAA,IACd,mBAAmB;AAAA,IACnB,kBAAkB;AAAA,MAChB;AAAA,EAEJ,QAAQ,MAAM,gBAAgB,UAAU,MAAM,uBAAa;AAAA,IACzD,OAAO,OAAO,cAAc,SAAS;AAAA,IACrC;AAAA,IACA,QAAQ,QAAQ,UAAU,UAAU;AAAA,IACpC;AAAA,IACA,iBAAiB;AAAA,IACjB;AAAA,IACA;AAAA,IACA;AAAA,IACA,wBAAwB;AAAA,MACtB,WAAW;AAAA,IACb;AAAA,EACF,CAAC;AAAA,EAED,IAAI,OAAO;AAAA,IACT,oBAAoB,SAAS,WAAW,QAAQ,KAAK;AAAA,EACvD;AAAA,EAEA,OAAO;AAAA;AAMT,eAAsB,eAAe,CACnC,SACA,QACiB;AAAA,EACjB,OAAO,wBACL,SACA,QACA,uBAAU,YACV,aACF;AAAA;AAMF,eAAsB,eAAe,CACnC,SACA,QACiB;AAAA,EACjB,OAAO,wBACL,SACA,QACA,uBAAU,YACV,aACF;AAAA;;AGpF6C,IAA/C;AAWA,eAAsB,mBAAmB,CACvC,SACA,QACmB;AAAA,EACnB,MAAM,qBAAqB,WACzB,SACA,0BACA,wBACF;AAAA,EACA,MAAM,qBAAqB,OAAO,SAChC,WAAW,SAAS,+BAA+B,MAAM,KAAK,QAC9D,EACF;AAAA,EAEA,IAAI,CAAC,OAAO,OAAO,wBAAW,EAAE,SAAS,kBAAkB,GAAG;AAAA,IAC5D,MAAM,WAAW,gCAAgC,uCAAuC,OAAO,OAAO,wBAAW,EAAE,KAAK,IAAI;AAAA,IAC5H,oBAAO,MAAM,QAAQ;AAAA,IACrB,MAAM,IAAI,MAAM,QAAQ;AAAA,EAC1B;AAAA,EACA,IAAI,WAAW,MAAM;AAAA,IACnB,oBAAO,MAAM,4CAA4C;AAAA,IACzD,MAAM,aAAa,MAAM,kBAAkB,EAAE,KAAK,CAAC;AAAA,IACnD,WAAW,KAAK;AAAA,IAChB,OAAO;AAAA,EACT;AAAA,EACA,IAAI;AAAA,EACJ,IAAI,OAAO,WAAW,UAAU;AAAA,IAC9B,OAAO;AAAA,EACT,EAAO,SAAI,OAAO,WAAW,YAAY,OAAO,MAAM;AAAA,IACpD,OAAO,OAAO;AAAA,EAChB,EAAO;AAAA,IACL,MAAM,WAAW;AAAA,IACjB,oBAAO,KAAK,QAAQ;AAAA,IACpB,MAAM,iBAAiB,MAAM,kBAAkB,EAAE,KAAK,CAAC;AAAA,IACvD,eAAe,KAAK;AAAA,IACpB,OAAO;AAAA;AAAA,EAET,IAAI,CAAC,KAAK,KAAK,GAAG;AAAA,IAChB,MAAM,WAAW;AAAA,IACjB,oBAAO,KAAK,QAAQ;AAAA,IACpB,MAAM,iBAAiB,MAAM,kBAAkB,EAAE,KAAK,CAAC;AAAA,IACvD,eAAe,KAAK;AAAA,IACpB,OAAO;AAAA,EACT;AAAA,EAEA,MAAM,mBAAmB,oBAAoB,OAAO;AAAA,EAEpD,IAAI;AAAA,IACF,MAAM,WAAW,MAAM,MAAM,GAAG,+BAA+B;AAAA,MAC7D,QAAQ;AAAA,MACR,SAAS;AAAA,WACJ,cAAc,SAAS,IAAI;AAAA,QAC9B,gBAAgB;AAAA,MAClB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,OAAO;AAAA,QACP,OAAO;AAAA,MACT,CAAC;AAAA,IACH,CAAC;AAAA,IAED,IAAI,CAAC,SAAS,IAAI;AAAA,MAChB,oBAAO,MACL,qBAAqB,SAAS,YAAY,SAAS,YACrD;AAAA,MACA,MAAM,IAAI,MACR,qBAAqB,SAAS,YAAY,SAAS,YACrD;AAAA,IACF;AAAA,IAEA,MAAM,OAAQ,MAAM,SAAS,KAAK;AAAA,IAKlC,IAAI,CAAC,MAAM,OAAO,IAAI,WAAW;AAAA,MAC/B,oBAAO,MAAM,gCAAgC;AAAA,MAC7C,MAAM,IAAI,MAAM,gCAAgC;AAAA,IAClD;AAAA,IAEA,MAAM,YAAY,KAAK,KAAK,GAAG;AAAA,IAE/B,IAAI,CAAC,MAAM,QAAQ,SAAS,KAAK,UAAU,WAAW,oBAAoB;AAAA,MACxE,MAAM,WAAW,oBAAoB,WAAW,UAAU,yCAAyC;AAAA,MACnG,oBAAO,MAAM,QAAQ;AAAA,MACrB,MAAM,iBAAiB,MAAM,kBAAkB,EAAE,KAAK,CAAC;AAAA,MACvD,eAAe,KAAK;AAAA,MACpB,OAAO;AAAA,IACT;AAAA,IAEA,IAAI,KAAK,OAAO;AAAA,MACd,MAAM,QAAQ;AAAA,QACZ,aAAa,KAAK,MAAM;AAAA,QACxB,cAAc;AAAA,QACd,aAAa,KAAK,MAAM;AAAA,MAC1B;AAAA,MAEA,oBAAoB,SAAS,uBAAU,gBAAgB,MAAM,KAAK;AAAA,IACpE;AAAA,IAEA,oBAAO,IAAI,mCAAmC,UAAU,QAAQ;AAAA,IAChE,OAAO;AAAA,IACP,OAAO,OAAgB;AAAA,IACvB,MAAM,UAAU,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,IACrE,oBAAO,MAAM,+BAA+B,SAAS;AAAA,IACrD,MAAM,iBAAiB,QAAQ,QAAQ,IAAI,MAAM,OAAO;AAAA;AAAA;;ACnH1B,IAAlC;AAgBA,eAAsB,qBAAqB,CACzC,SACA,QAKsC;AAAA,EACtC,MAAM,IAAI,OAAO,KAAK;AAAA,EACtB,MAAM,OAAO,OAAO,QAAQ;AAAA,EAC5B,MAAM,SAAS,OAAO;AAAA,EACtB,MAAM,YAAY,WAChB,SACA,sBACA,aACF;AAAA,EACA,oBAAO,IAAI,+BAA+B,WAAW;AAAA,EAErD,MAAM,UAAU,WAAW,OAAO;AAAA,EAElC,IAAI;AAAA,IACF,MAAM,WAAW,MAAM,MAAM,GAAG,8BAA8B;AAAA,MAC5D,QAAQ;AAAA,MACR,SAAS;AAAA,WACJ,cAAc,OAAO;AAAA,QACxB,gBAAgB;AAAA,MAClB;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB,OAAO;AAAA,QACP;AAAA,QACA;AAAA,QACA;AAAA,MACF,CAAC;AAAA,IACH,CAAC;AAAA,IAED,IAAI,CAAC,SAAS,IAAI;AAAA,MAChB,MAAM,IAAI,MAAM,6BAA6B,SAAS,YAAY;AAAA,IACpE;AAAA,IAEA,MAAM,OAAO,MAAM,SAAS,KAAK;AAAA,IACjC,MAAM,YAAY;AAAA,IAElB,OAAO;AAAA,IACP,OAAO,OAAgB;AAAA,IACvB,MAAM,UAAU,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,IACrE,MAAM;AAAA;AAAA;AAOV,eAAsB,sBAAsB,CAC1C,SACA,QACgD;AAAA,EAChD,IAAI;AAAA,EACJ,IAAI;AAAA,EACJ,MAAM,YAAY,yBAAyB,OAAO;AAAA,EAClD,oBAAO,IAAI,2CAA2C,WAAW;AAAA,EACjE,MAAM,YAAY,OAAO,SACvB,WAAW,SAAS,uCAAuC,MAAM,KAC/D,QACF,EACF;AAAA,EAEA,MAAM,iBACJ;AAAA,EAEF,IAAI,OAAO,WAAW,UAAU;AAAA,IAC9B,WAAW;AAAA,IACX,aAAa;AAAA,EACf,EAAO;AAAA,IACL,WAAW,OAAO;AAAA,IAClB,aAAa,OAAO,UAAU;AAAA;AAAA,EAGhC,MAAM,WAAW;AAAA,IACf;AAAA,MACE,MAAM;AAAA,MACN,SAAS;AAAA,QACP,EAAE,MAAM,QAAQ,MAAM,WAAW;AAAA,QACjC,EAAE,MAAM,aAAa,WAAW,EAAE,KAAK,SAAS,EAAE;AAAA,MACpD;AAAA,IACF;AAAA,EACF;AAAA,EAEA,MAAM,UAAU,WAAW,OAAO;AAAA,EAElC,IAAI;AAAA,IACF,MAAM,cAAmC;AAAA,MACvC,OAAO;AAAA,MACP;AAAA,MACA,YAAY;AAAA,IACd;AAAA,IAEA,MAAM,WAAW,MAAM,MAAM,GAAG,4BAA4B;AAAA,MAC1D,QAAQ;AAAA,MACR,SAAS;AAAA,QACP,gBAAgB;AAAA,WACb,cAAc,OAAO;AAAA,MAC1B;AAAA,MACA,MAAM,KAAK,UAAU,WAAW;AAAA,IAClC,CAAC;AAAA,IAED,IAAI,CAAC,SAAS,IAAI;AAAA,MAChB,MAAM,IAAI,MAAM,qBAAqB,SAAS,QAAQ;AAAA,IACxD;AAAA,IAEA,MAAM,SAAkB,MAAM,SAAS,KAAK;AAAA,IAc5C,MAAM,cAAc;AAAA,IACpB,MAAM,UAAU,YAAY,UAAU,IAAI,SAAS;AAAA,IAEnD,IAAI,YAAY,OAAO;AAAA,MACrB,oBACE,SACA,uBAAU,mBACV,OAAO,WAAW,WAAW,SAAS,OAAO,UAAU,IACvD;AAAA,QACE,aAAa,YAAY,MAAM;AAAA,QAC/B,cAAc,YAAY,MAAM;AAAA,QAChC,aAAa,YAAY,MAAM;AAAA,MACjC,CACF;AAAA,IACF;AAAA,IAEA,IAAI,CAAC,SAAS;AAAA,MACZ,OAAO;AAAA,QACL,OAAO;AAAA,QACP,aAAa;AAAA,MACf;AAAA,IACF;AAAA,IAGA,MAAM,iBACJ,OAAO,WAAW,YAClB,QAAQ,OAAO,MAAM,KACrB,OAAO,WAAW;AAAA,IAGpB,IAAI,gBAAgB;AAAA,MAClB,OAAO;AAAA,IACT;AAAA,IAGA,MAAM,aAAa,QAAQ,MAAM,2BAA2B;AAAA,IAC5D,MAAM,QAAQ,aAAa,IAAI,KAAK;AAAA,IACpC,IAAI,CAAC,OAAO;AAAA,MACV,oBAAO,KAAK,yDAAyD;AAAA,IACvE;AAAA,IACA,MAAM,aAAa,SAAS;AAAA,IAC5B,MAAM,cAAc,QAAQ,QAAQ,6BAA6B,EAAE,EAAE,KAAK;AAAA,IAE1E,MAAM,kBAAkB,EAAE,OAAO,YAAY,YAAY;AAAA,IACzD,OAAO;AAAA,IACP,OAAO,OAAgB;AAAA,IACvB,MAAM,UAAU,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,IACrE,oBAAO,MAAM,0BAA0B,SAAS;AAAA,IAChD,OAAO;AAAA,MACL,OAAO;AAAA,MACP,aAAa,UAAU;AAAA,IACzB;AAAA;AAAA;;AC9LmB,IAAvB;;;ACDuB,IAAvB;AAEA,IAAM,cAAc;AAAA,EAClB,KAAK;AAAA,IACH,QAAQ,CAAC,IAAM,IAAM,IAAM,EAAI;AAAA,IAC/B,YAAY,CAAC,IAAM,IAAM,IAAM,EAAI;AAAA,EACrC;AAAA,EACA,SAAS,CAAC,IAAM,IAAM,EAAI;AAAA,EAC1B,KAAK,CAAC,IAAM,KAAM,KAAM,EAAI;AAAA,EAC5B,MAAM,CAAC,KAAM,IAAM,IAAM,EAAI;AAAA,EAC7B,MAAM,CAAC,KAAM,KAAM,KAAM,GAAI;AAAA,EAC7B,WAAW,CAAC,IAAM,IAAM,KAAM,GAAI;AACpC;AAEA,SAAS,UAAU,CACjB,QACA,QACA,OACS;AAAA,EACT,SAAS,IAAI,EAAG,IAAI,MAAM,QAAQ,KAAK;AAAA,IACrC,IAAI,OAAO,SAAS,OAAO,MAAM;AAAA,MAAK,OAAO;AAAA,EAC/C;AAAA,EACA,OAAO;AAAA;AAQF,SAAS,mBAAmB,CAAC,QAAwB;AAAA,EAC1D,IAAI,OAAO,SAAS,IAAI;AAAA,IACtB,OAAO;AAAA,EACT;AAAA,EAIA,IACE,WAAW,QAAQ,GAAG,YAAY,IAAI,MAAM,KAC5C,WAAW,QAAQ,GAAG,YAAY,IAAI,UAAU,GAChD;AAAA,IACA,OAAO;AAAA,EACT;AAAA,EAGA,IACE,WAAW,QAAQ,GAAG,YAAY,OAAO,KACxC,OAAO,OAAO,QAAS,OAAO,KAAK,SAAU,KAC9C;AAAA,IACA,OAAO;AAAA,EACT;AAAA,EAGA,IAAI,WAAW,QAAQ,GAAG,YAAY,GAAG,GAAG;AAAA,IAC1C,OAAO;AAAA,EACT;AAAA,EAGA,IAAI,WAAW,QAAQ,GAAG,YAAY,IAAI,GAAG;AAAA,IAC3C,OAAO;AAAA,EACT;AAAA,EAGA,IAAI,WAAW,QAAQ,GAAG,YAAY,IAAI,GAAG;AAAA,IAC3C,OAAO;AAAA,EACT;AAAA,EAGA,IAAI,WAAW,QAAQ,GAAG,YAAY,SAAS,GAAG;AAAA,IAChD,OAAO;AAAA,EACT;AAAA,EAGA,oBAAO,KACL,sEACF;AAAA,EACA,OAAO;AAAA;AAQT,eAAsB,qBAAqB,CACzC,WACA;AAAA,EACA,IAAI;AAAA,IAEF,QAAQ,aAAa,MAAa;AAAA,IAClC,MAAM,SAAS,UAAU,UAAU;AAAA,IAEnC,OAAO,IAAI,SAAS;AAAA,WACZ,KAAI,GAAG;AAAA,QACX,IAAI;AAAA,UACF,QAAQ,MAAM,UAAU,MAAM,OAAO,KAAK;AAAA,UAC1C,IAAI,MAAM;AAAA,YACR,KAAK,KAAK,IAAI;AAAA,UAChB,EAAO;AAAA,YAEL,KAAK,KAAK,KAAK;AAAA;AAAA,UAEjB,OAAO,OAAO;AAAA,UACd,KAAK,QAAQ,KAAc;AAAA;AAAA;AAAA,MAG/B,OAAO,CAAC,OAAO,UAAU;AAAA,QACvB,OAAO,OAAO,EAAE,QAAQ,MAAM,SAAS,KAAK,CAAC;AAAA;AAAA,IAEjD,CAAC;AAAA,IACD,OAAO,OAAO;AAAA,IACd,MAAM,UAAU,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,IACrE,oBAAO,MAAM,sCAAsC,SAAS;AAAA,IAC5D,MAAM,IAAI,MACR,qGACF;AAAA;AAAA;;;ADlGJ,eAAe,iBAAiB,CAC9B,SACA,SACA;AAAA,EACA,MAAM,eAAe,WACnB,SACA,oBACA,iBACF;AAAA,EACA,MAAM,eAAe,WAAW,SAAS,oBAAoB,MAAM;AAAA,EACnE,MAAM,sBAAsB,WAC1B,SACA,2BACA,EACF;AAAA,EACA,MAAM,UAAU,WAAW,OAAO;AAAA,EAElC,MAAM,QAAQ,QAAQ,SAAU;AAAA,EAChC,MAAM,QAAQ,QAAQ,SAAU;AAAA,EAChC,MAAM,eAAe,QAAQ,gBAAiB;AAAA,EAC9C,MAAM,SAAS,QAAQ,UAAU;AAAA,EAEjC,IAAI;AAAA,IACF,MAAM,MAAM,MAAM,MAAM,GAAG,wBAAwB;AAAA,MACjD,QAAQ;AAAA,MACR,SAAS;AAAA,WACJ,cAAc,OAAO;AAAA,QACxB,gBAAgB;AAAA,WAEZ,WAAW,QAAQ,EAAE,QAAQ,aAAa,IAAI,CAAC;AAAA,MACrD;AAAA,MACA,MAAM,KAAK,UAAU;AAAA,QACnB;AAAA,QACA;AAAA,QACA,OAAO,QAAQ;AAAA,QACf;AAAA,WACI,gBAAgB,EAAE,aAAa;AAAA,MACrC,CAAC;AAAA,IACH,CAAC;AAAA,IAED,IAAI,CAAC,IAAI,IAAI;AAAA,MACX,MAAM,MAAM,MAAM,IAAI,KAAK;AAAA,MAC3B,MAAM,IAAI,MAAM,oBAAoB,IAAI,WAAW,KAAK;AAAA,IAC1D;AAAA,IAGA,IAAI,CAAC,IAAI,MAAM;AAAA,MACb,MAAM,IAAI,MAAM,kCAAkC;AAAA,IACpD;AAAA,IAIA,IAAI,CAAC,UAAU,GAAG;AAAA,MAChB,OAAO,MAAM,sBAAsB,IAAI,IAAI;AAAA,IAC7C;AAAA,IAEA,OAAO,IAAI;AAAA,IACX,OAAO,KAAc;AAAA,IACrB,MAAM,UAAU,eAAe,QAAQ,IAAI,UAAU,OAAO,GAAG;AAAA,IAC/D,MAAM,IAAI,MAAM,2CAA2C,SAAS;AAAA;AAAA;AAOxE,eAAsB,mBAAmB,CACvC,SACA,OACiB;AAAA,EACjB,IAAI,YAAY,WACd,SACA,8BACA,wBACF;AAAA,EACA,oBAAO,IAAI,uCAAuC,WAAW;AAAA,EAE7D,MAAM,UAAU,WAAW,OAAO;AAAA,EAGlC,IAAI;AAAA,EACJ,IAAI,cAAgD;AAAA,EAEpD,IAAI,iBAAiB,QAAQ,iBAAiB,MAAM;AAAA,IAClD,OAAO;AAAA,EACT,EAAO,SAAI,OAAO,SAAS,KAAK,GAAG;AAAA,IAGjC,MAAM,mBAAmB,oBAAoB,KAAK;AAAA,IAClD,oBAAO,MAAM,kCAAkC,kBAAkB;AAAA,IAEjE,MAAM,aAAa,IAAI,WAAW,KAAK;AAAA,IACvC,OAAO,IAAI,KAAK,CAAC,UAAU,GAAG,EAAE,MAAM,iBAAiB,CAAC;AAAA,EAC1D,EAAO,SACL,OAAO,UAAU,YACjB,UAAU,QACT,MAAc,SAAS,MACxB;AAAA,IACA,MAAM,SAAS;AAAA,IACf,IACE,EAAE,OAAO,iBAAiB,SAC1B,EAAE,OAAO,iBAAiB,SAC1B,CAAC,OAAO,SAAS,OAAO,KAAK,GAC7B;AAAA,MACA,MAAM,IAAI,MACR,yDACF;AAAA,IACF;AAAA,IAEA,IAAI,OAAO,SAAS,OAAO,KAAK,GAAG;AAAA,MAEjC,IAAI,WAAW,OAAO;AAAA,MACtB,IAAI,CAAC,UAAU;AAAA,QACb,WAAW,oBAAoB,OAAO,KAAK;AAAA,QAC3C,oBAAO,MAAM,kCAAkC,UAAU;AAAA,MAC3D,EAAO;AAAA,QACL,oBAAO,MAAM,6BAA6B,UAAU;AAAA;AAAA,MAGtD,MAAM,aAAa,IAAI,WAAW,OAAO,KAAK;AAAA,MAC9C,OAAO,IAAI,KAAK,CAAC,UAAU,GAAG,EAAE,MAAM,SAAS,CAAC;AAAA,IAClD,EAAO;AAAA,MACL,OAAO,OAAO;AAAA;AAAA,IAEhB,cAAc;AAAA,IACd,IAAI,OAAO,OAAO,UAAU,YAAY,OAAO,OAAO;AAAA,MACpD,YAAY,OAAO;AAAA,IACrB;AAAA,EACF,EAAO;AAAA,IACL,MAAM,IAAI,MACR,mLACF;AAAA;AAAA,EAGF,MAAM,OAAQ,KAAc,QAAQ;AAAA,EACpC,MAAM,WACH,KAAc,SACd,KAAK,SAAS,KAAK,KAAK,KAAK,SAAS,MAAM,IACzC,kBACA,KAAK,SAAS,KAAK,IACjB,kBACA,KAAK,SAAS,KAAK,IACjB,kBACA,KAAK,SAAS,MAAM,IAClB,mBACA;AAAA,EAEZ,MAAM,WAAW,IAAI;AAAA,EACrB,SAAS,OAAO,QAAQ,MAAM,QAAQ;AAAA,EACtC,SAAS,OAAO,SAAS,OAAO,SAAS,CAAC;AAAA,EAC1C,IAAI,aAAa;AAAA,IACf,IAAI,OAAO,YAAY,aAAa,UAAU;AAAA,MAC5C,SAAS,OAAO,YAAY,OAAO,YAAY,QAAQ,CAAC;AAAA,IAC1D;AAAA,IACA,IAAI,OAAO,YAAY,oBAAoB,UAAU;AAAA,MACnD,SAAS,OAAO,mBAAmB,OAAO,YAAY,eAAe,CAAC;AAAA,IACxE;AAAA,IACA,IAAI,OAAO,YAAY,WAAW,UAAU;AAAA,MAC1C,SAAS,OAAO,UAAU,OAAO,YAAY,MAAM,CAAC;AAAA,IACtD;AAAA,IACA,IAAI,OAAO,YAAY,gBAAgB,UAAU;AAAA,MAC/C,SAAS,OAAO,eAAe,OAAO,YAAY,WAAW,CAAC;AAAA,IAChE;AAAA,IACA,IAAI,MAAM,QAAQ,YAAY,sBAAsB,GAAG;AAAA,MACrD,WAAW,KAAK,YAAY,wBAAwB;AAAA,QAClD,SAAS,OAAO,6BAA6B,OAAO,CAAC,CAAC;AAAA,MACxD;AAAA,IACF;AAAA,EACF;AAAA,EAEA,IAAI;AAAA,IACF,MAAM,WAAW,MAAM,MAAM,GAAG,gCAAgC;AAAA,MAC9D,QAAQ;AAAA,MACR,SAAS;AAAA,WACJ,cAAc,OAAO;AAAA,MAC1B;AAAA,MACA,MAAM;AAAA,IACR,CAAC;AAAA,IAED,IAAI,CAAC,SAAS,IAAI;AAAA,MAChB,MAAM,IAAI,MACR,+BAA+B,SAAS,UAAU,SAAS,YAC7D;AAAA,IACF;AAAA,IAEA,MAAM,OAAQ,MAAM,SAAS,KAAK;AAAA,IAClC,OAAO,KAAK,QAAQ;AAAA,IACpB,OAAO,OAAgB;AAAA,IACvB,MAAM,UAAU,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,IACrE,oBAAO,MAAM,wBAAwB,SAAS;AAAA,IAC9C,MAAM;AAAA;AAAA;AAOV,eAAsB,kBAAkB,CACtC,SACA,OAC6D;AAAA,EAE7D,MAAM,UACJ,OAAO,UAAU,WACb,EAAE,MAAM,MAAM,IACb;AAAA,EAEP,MAAM,gBACJ,QAAQ,SACP,WAAW,SAAS,oBAAoB,iBAAiB;AAAA,EAC5D,oBAAO,IAAI,wCAAwC,eAAe;AAAA,EAClE,IAAI;AAAA,IACF,MAAM,eAAe,MAAM,kBAAkB,SAAS,OAAO;AAAA,IAC7D,OAAO;AAAA,IACP,OAAO,OAAgB;AAAA,IACvB,MAAM,UAAU,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,IACrE,oBAAO,MAAM,4BAA4B,SAAS;AAAA,IAClD,MAAM;AAAA;AAAA;;AErOwB,IAAlC;AAC+C,IAA/C;;;ACNuB,IAAvB;AAC+B,IAA/B;AAKO,SAAS,qBAAqB,GAGR;AAAA,EAC3B,OAAO,SAAS,MAAM,YAA8C;AAAA,IAClE,IAAI;AAAA,MACF,IAAI,iBAAiB,2BAAgB;AAAA,QACnC,MAAM,cAAc,KAAK,QAAQ,wBAAwB,EAAE;AAAA,QAC3D,KAAK,MAAM,WAAW;AAAA,QACtB,OAAO;AAAA,MACT;AAAA,MACA,OAAO;AAAA,MACP,OAAO,WAAoB;AAAA,MAC3B,MAAM,UACJ,qBAAqB,QAAQ,UAAU,UAAU,OAAO,SAAS;AAAA,MACnE,oBAAO,KAAK,+BAA+B,SAAS;AAAA,MACpD,OAAO;AAAA;AAAA;AAAA;;;ADPb,eAAe,yBAAyB,CACtC,SACA,QACA,WACA,YACoB;AAAA,EACpB,MAAM,SAAS,mBAAmB,OAAO;AAAA,EACzC,MAAM,YAAY,WAAW,OAAO;AAAA,EACpC,qBAAO,IAAI,kBAAkB,oBAAoB,WAAW;AAAA,EAC5D,MAAM,cAAc,OAAO,eAAe;AAAA,EAC1C,MAAM,gBAAgB,CAAC,CAAC,OAAO;AAAA,EAE/B,IAAI,eAAe;AAAA,IACjB,qBAAO,KACL,4HACF;AAAA,EACF;AAAA,EAEA,IAAI;AAAA,IACF,QAAQ,QAAQ,UAAU,MAAM,0BAAe;AAAA,MAC7C,OAAO,OAAO,cAAc,SAAS;AAAA,MACrC,QAAQ;AAAA,MACR,QAAQ,OAAO;AAAA,MACf;AAAA,MACA,yBAAyB,sBAAsB;AAAA,IACjD,CAAC;AAAA,IAED,IAAI,OAAO;AAAA,MACT,oBAAoB,SAAS,WAAW,OAAO,QAAQ,KAAK;AAAA,IAC9D;AAAA,IACA,OAAO;AAAA,IACP,OAAO,OAAgB;AAAA,IACvB,MAAM,UAAU,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,IACrE,qBAAO,MAAM,2BAA2B,SAAS;AAAA,IACjD,MAAM;AAAA;AAAA;AAOV,eAAsB,iBAAiB,CACrC,SACA,QACoB;AAAA,EACpB,OAAO,0BACL,SACA,QACA,wBAAU,cACV,aACF;AAAA;AAMF,eAAsB,iBAAiB,CACrC,SACA,QACoB;AAAA,EACpB,OAAO,0BACL,SACA,QACA,wBAAU,cACV,aACF;AAAA;;AE3EwB,IAA1B;;;ACJ0B,IAA1B;AACyF,IAAzF;AAGA,SAAS,wBAAwB,CAC/B,WACqC;AAAA,EACrC,MAAM,aAAa,UAAU,YAAY;AAAA,EACzC,MAAM,mBAAqC,WAAW,SAAS,IAAI,IAC/D,eACA;AAAA,EAEJ,IAAI;AAAA,IACF,OAAO,oCAAiB,SAA0B;AAAA,IAClD,OAAO,OAAgB;AAAA,IAEvB,OAAO,+BAAY,gBAAgB;AAAA;AAAA;AAWvC,eAAsB,YAAY,CAChC,SACA,OACA,QACA;AAAA,EACA,MAAM,YACJ,UAAU,wBAAU,aAChB,cAAc,OAAO,IACrB,cAAc,OAAO;AAAA,EAC3B,MAAM,SAAS,yBAAyB,SAAS,EAAE,OAAO,MAAM;AAAA,EAChE,OAAO;AAAA;AAUT,eAAsB,cAAc,CAClC,SACA,OACA,QACA;AAAA,EACA,MAAM,YACJ,UAAU,wBAAU,aAChB,cAAc,OAAO,IACrB,cAAc,OAAO;AAAA,EAC3B,OAAO,yBAAyB,SAAS,EAAE,OAAO,MAAM;AAAA;;;AD9C1D,eAAsB,qBAAqB,CACzC,WACE,QAAQ,YAAY,wBAAU,cACb;AAAA,EACnB,OAAO,MAAM,aAAa,SAAS,WAAW,MAAM;AAAA;AAMtD,eAAsB,qBAAqB,CACzC,WACE,QAAQ,YAAY,wBAAU,cACf;AAAA,EACjB,OAAO,MAAM,eAAe,SAAS,WAAW,MAAM;AAAA;;AZQjD,IAAM,eAAuB;AAAA,EAClC,MAAM;AAAA,EACN,aAAa;AAAA,EACb,QAAQ;AAAA,IACN,gBAAgB,QAAQ,IAAI;AAAA,IAC5B,iBAAiB,QAAQ,IAAI;AAAA,IAC7B,oBAAoB,QAAQ,IAAI;AAAA,IAChC,oBAAoB,QAAQ,IAAI;AAAA,IAChC,aAAa,QAAQ,IAAI;AAAA,IACzB,aAAa,QAAQ,IAAI;AAAA,IACzB,wBAAwB,QAAQ,IAAI;AAAA,IACpC,0BAA0B,QAAQ,IAAI;AAAA,IACtC,sBAAsB,QAAQ,IAAI;AAAA,IAClC,6BAA6B,QAAQ,IAAI;AAAA,IACzC,gCAAgC,QAAQ,IAAI;AAAA,IAC5C,qCACE,QAAQ,IAAI;AAAA,IACd,+BAA+B,QAAQ,IAAI;AAAA,EAC7C;AAAA,OACM,KAAI,CAAC,SAAS,SAAS;AAAA,IAI3B,iBAAiB,SAAS,OAAO;AAAA;AAAA,EAGnC,QAAQ;AAAA,KACL,wBAAU,iBAAiB,OAC1B,SACA,WACG;AAAA,MACH,OAAO,oBAAoB,SAAS,MAAM;AAAA;AAAA,KAE3C,wBAAU,wBAAwB,OACjC,SACA,WACG;AAAA,MACH,OAAO,sBAAsB,SAAS,MAAM;AAAA;AAAA,KAE7C,wBAAU,wBAAwB,OACjC,SACA,WACG;AAAA,MACH,OAAO,sBAAsB,SAAS,MAAM;AAAA;AAAA,KAE7C,wBAAU,aAAa,OACtB,SACA,WACG;AAAA,MACH,OAAO,gBAAgB,SAAS,MAAM;AAAA;AAAA,KAEvC,wBAAU,aAAa,OACtB,SACA,WACG;AAAA,MACH,OAAO,gBAAgB,SAAS,MAAM;AAAA;AAAA,KAEvC,wBAAU,QAAQ,OACjB,SACA,WAKG;AAAA,MACH,OAAO,sBAAsB,SAAS,MAAM;AAAA;AAAA,KAE7C,wBAAU,oBAAoB,OAC7B,SACA,WACG;AAAA,MACH,OAAO,uBAAuB,SAAS,MAAM;AAAA;AAAA,KAE9C,wBAAU,gBAAgB,OACzB,SACA,UACG;AAAA,MACH,OAAO,oBAAoB,SAAS,KAAK;AAAA;AAAA,KAE1C,wBAAU,iBAAiB,OAC1B,SACA,UACG;AAAA,MACH,OAAO,mBAAmB,SAAS,KAAK;AAAA;AAAA,KAEzC,wBAAU,eAAe,OACxB,SACA,WACG;AAAA,MACH,OAAO,kBAAkB,SAAS,MAAM;AAAA;AAAA,KAEzC,wBAAU,eAAe,OACxB,SACA,WACG;AAAA,MACH,OAAO,kBAAkB,SAAS,MAAM;AAAA;AAAA,EAE5C;AAAA,EACA,OAAO;AAAA,IACL;AAAA,MACE,MAAM;AAAA,MACN,OAAO;AAAA,QACL;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAA2B;AAAA,YACpC,MAAM,UAAU,WAAW,OAAO;AAAA,YAClC,MAAM,WAAW,MAAM,MAAM,GAAG,kBAAkB;AAAA,cAChD,SAAS,cAAc,OAAO;AAAA,YAChC,CAAC;AAAA,YACD,MAAM,OAAO,MAAM,SAAS,KAAK;AAAA,YACjC,qBAAO,IACL,EAAE,MAAO,MAA+B,MAAM,UAAU,MAAM,GAC9D,kBACF;AAAA,YACA,IAAI,CAAC,SAAS,IAAI;AAAA,cAChB,MAAM,IAAI,MACR,sCAAsC,SAAS,YACjD;AAAA,YACF;AAAA;AAAA,QAEJ;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAA2B;AAAA,YACpC,IAAI;AAAA,cACF,MAAM,YAAY,MAAM,QAAQ,SAC9B,wBAAU,gBACV;AAAA,gBACE,MAAM;AAAA,cACR,CACF;AAAA,cACA,qBAAO,IAAI,EAAE,UAAU,GAAG,WAAW;AAAA,cACrC,OAAO,OAAgB;AAAA,cACvB,MAAM,UACJ,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,cACvD,qBAAO,MAAM,iCAAiC,SAAS;AAAA,cACvD,MAAM;AAAA;AAAA;AAAA,QAGZ;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAA2B;AAAA,YACpC,IAAI;AAAA,cACF,MAAM,OAAO,MAAM,QAAQ,SAAS,wBAAU,YAAY;AAAA,gBACxD,QAAQ;AAAA,cACV,CAAC;AAAA,cACD,IAAI,KAAK,WAAW,GAAG;AAAA,gBACrB,MAAM,IAAI,MAAM,yBAAyB;AAAA,cAC3C;AAAA,cACA,qBAAO,IAAI,EAAE,KAAK,GAAG,gCAAgC;AAAA,cACrD,OAAO,OAAgB;AAAA,cACvB,MAAM,UACJ,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,cACvD,qBAAO,MAAM,6BAA6B,SAAS;AAAA,cACnD,MAAM;AAAA;AAAA;AAAA,QAGZ;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAA2B;AAAA,YACpC,IAAI;AAAA,cACF,MAAM,OAAO,MAAM,QAAQ,SAAS,wBAAU,YAAY;AAAA,gBACxD,QAAQ;AAAA,cACV,CAAC;AAAA,cACD,IAAI,KAAK,WAAW,GAAG;AAAA,gBACrB,MAAM,IAAI,MAAM,yBAAyB;AAAA,cAC3C;AAAA,cACA,qBAAO,IAAI,EAAE,KAAK,GAAG,gCAAgC;AAAA,cACrD,OAAO,OAAgB;AAAA,cACvB,MAAM,UACJ,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,cACvD,qBAAO,MAAM,6BAA6B,SAAS;AAAA,cACnD,MAAM;AAAA;AAAA;AAAA,QAGZ;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAA2B;AAAA,YACpC,qBAAO,IAAI,8BAA8B;AAAA,YACzC,IAAI;AAAA,cACF,MAAM,QAAQ,MAAM,QAAQ,SAAS,wBAAU,OAAO;AAAA,gBACpD,QAAQ;AAAA,gBACR,GAAG;AAAA,gBACH,MAAM;AAAA,cACR,CAAC;AAAA,cACD,qBAAO,IAAI,EAAE,MAAM,GAAG,sCAAsC;AAAA,cAC5D,OAAO,OAAgB;AAAA,cACvB,MAAM,UACJ,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,cACvD,qBAAO,MAAM,mCAAmC,SAAS;AAAA,cACzD,MAAM;AAAA;AAAA;AAAA,QAGZ;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAA2B;AAAA,YACpC,IAAI;AAAA,cACF,qBAAO,IAAI,+BAA+B;AAAA,cAC1C,IAAI;AAAA,gBACF,MAAM,SAAS,MAAM,QAAQ,SAC3B,wBAAU,mBACV,mLACF;AAAA,gBAEA,IACE,UACA,OAAO,WAAW,YAClB,WAAW,UACX,iBAAiB,QACjB;AAAA,kBACA,qBAAO,IAAI,EAAE,OAAO,GAAG,mBAAmB;AAAA,gBAC5C,EAAO;AAAA,kBACL,qBAAO,MACL,4CACA,MACF;AAAA;AAAA,gBAEF,OAAO,GAAY;AAAA,gBACnB,MAAM,UAAU,aAAa,QAAQ,EAAE,UAAU,OAAO,CAAC;AAAA,gBACzD,qBAAO,MAAM,oCAAoC,SAAS;AAAA;AAAA,cAE5D,OAAO,GAAY;AAAA,cACnB,MAAM,UAAU,aAAa,QAAQ,EAAE,UAAU,OAAO,CAAC;AAAA,cACzD,qBAAO,MACL,2CAA2C,SAC7C;AAAA;AAAA;AAAA,QAGN;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAA2B;AAAA,YACpC,qBAAO,IAAI,2BAA2B;AAAA,YACtC,IAAI;AAAA,cACF,MAAM,WAAW,MAAM,MACrB,+EACF;AAAA,cACA,MAAM,cAAc,MAAM,SAAS,YAAY;AAAA,cAC/C,MAAM,gBAAgB,MAAM,QAAQ,SAClC,wBAAU,eACV,OAAO,KAAK,IAAI,WAAW,WAAW,CAAC,CACzC;AAAA,cACA,qBAAO,IACL,EAAE,cAAc,GAChB,mCACF;AAAA,cACA,OAAO,OAAgB;AAAA,cACvB,MAAM,UACJ,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,cACvD,qBAAO,MAAM,gCAAgC,SAAS;AAAA,cACtD,MAAM;AAAA;AAAA;AAAA,QAGZ;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAA2B;AAAA,YACpC,MAAM,SAAS;AAAA,YACf,MAAM,SAAS,MAAM,QAAQ,SAC3B,wBAAU,uBACV,EAAE,OAAO,CACX;AAAA,YACA,IAAI,CAAC,MAAM,QAAQ,MAAM,KAAK,OAAO,WAAW,GAAG;AAAA,cACjD,MAAM,IAAI,MACR,6DACF;AAAA,YACF;AAAA,YACA,qBAAO,IAAI,EAAE,OAAO,GAAG,kBAAkB;AAAA;AAAA,QAE7C;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAA2B;AAAA,YACpC,MAAM,SAAS;AAAA,YACf,MAAM,SAAS,MAAM,QAAQ,SAC3B,wBAAU,uBACV,EAAE,OAAO,CACX;AAAA,YACA,MAAM,cAAc,MAAM,QAAQ,SAChC,wBAAU,uBACV;AAAA,cACE;AAAA,YACF,CACF;AAAA,YACA,IAAI,gBAAgB,QAAQ;AAAA,cAC1B,MAAM,IAAI,MACR,mDAAmD,iBAAiB,cACtE;AAAA,YACF;AAAA,YACA,qBAAO,IAAI,EAAE,YAAY,GAAG,cAAc;AAAA;AAAA,QAE9C;AAAA,QACA;AAAA,UACE,MAAM;AAAA,UACN,IAAI,OAAO,YAA2B;AAAA,YACpC,IAAI;AAAA,cACF,MAAM,WAAW,MAAM,QAAQ,SAC7B,wBAAU,gBACV;AAAA,gBACE,MAAM;AAAA,cACR,CACF;AAAA,cACA,IAAI,CAAC,UAAU;AAAA,gBACb,MAAM,IAAI,MAAM,2BAA2B;AAAA,cAC7C;AAAA,cACA,qBAAO,IAAI,+BAA+B;AAAA,cAC1C,OAAO,OAAgB;AAAA,cACvB,MAAM,UACJ,iBAAiB,QAAQ,MAAM,UAAU,OAAO,KAAK;AAAA,cACvD,qBAAO,MAAM,wCAAwC,SAAS;AAAA,cAC9D,MAAM;AAAA;AAAA;AAAA,QAGZ;AAAA,MACF;AAAA,IACF;AAAA,EACF;AACF;AAEA,IAAe;",
  "debugId": "9B5BF59394995A3864756E2164756E21",
  "names": []
}